% Chapter Template

% Main chapter title
%\chapter[toc version]{doc version}
\chapter{Multi-source domain adaptation}

% Short version of the title for the header
%\chaptermark{version for header}

% Chapter Label
% For referencing this chapter elsewhere, use \ref{ChapterTemplate}
\label{chp:domain_adaptation}

% Write text in here
% Use \subsection and \subsubsection to organize text

\begin{tcolorbox}
	\small{
		Some parts of this chapter were originally published in or adapted from:
		\begin{itemize}
			\item[] \cite{ThesisFrancisco} \bibentry{ThesisFrancisco} (presented in \Secref{sec:da_sensors})
			\item[] \cite{MODAFM} \bibentry{MODAFM} (presented in \Secref{sec:modafm})
		\end{itemize}
		
		The Master's thesis \cite{ThesisFrancisco} was supervised by Jaime S. Cardoso and co-supervised by Diogo Pernes.
	}
\end{tcolorbox}

\section{Introduction}
\label{sec:chp3_intro}
In Chapter \ref{chp:networked_data_streams}, we have addressed the situation where the set of entities was the same at training and testing time. The goal there was to exploit inter-correlations between entities to learn better generative models for each individual entity. Now, we focus on the problem of learning a discriminative model for one particular entity (the \newterm{target}) for which no annotated data is available. Assuming some invariance properties, we can hope to accomplish this task by learning a discriminative model using the combination of annotated data from the remaining entities (the \newterm{sources}) and unlabeled data from the target entity. Since entities do not need to (and generally do not) correspond to physical objects and may refer to different contexts where the data was collected, they are more commonly called \newterm{domains} and the problem itself is known as \newterm{domain adaptation} (DA). In the following, we motivate the practical importance of this problem and summarize our contributions.

Supervised training of deep neural networks has achieved outstanding results on multiple learning tasks greatly due to the availability of large and rich annotated datasets. Unfortunately, annotating such large-scale datasets is often prohibitively time-consuming and expensive. Furthermore, in many practical cases, it is not possible to collect annotated data with the same characteristics as the test data, and, as a result, training and test data are drawn from distinct underlying distributions. As a consequence, the model performance tends to decrease significantly on the test data. The goal of DA algorithms is to minimize this gap by finding transferable knowledge from the source to the target domain. Sometimes, it is assumed that a small portion of labeled target data are available at training time -- a setting that is known as \newterm{semi-supervised} DA (e.g.\ \citet{Daume2010, Donahue2013, Kumar2010, Saito2019, Yao2015}). In this chapter, we focus mostly on the more challenging scenario, where no labeled target data are available for training -- known as \newterm{unsupervised} DA (e.g.\ \citet{Baktashmotlagh2013, Ganin2015, Kang2019, Long2016, Zhao2018}). The DA problem, in its semi-supervised and unsupervised variants, has received increased attention in recent years, both from theoretical (e.g.\ \citet{BenDavid2010, BenDavid2007, Blitzer2008, Cortes2014, Gopalan2013, Hoffman2018, Zhao2019}) and algorithmic perspectives (e.g.\ \citet{Ajakan2014, Becker2013, Fernando2013, Jhuo2012, Long2015, Louizos2015, Sun2016, Tzeng2017}). In many situations, the annotated training data may consist of a combination of distinct datasets, some of which may be closer or further away from the target data. Finding nontrivial ways of combining multiple datasets to approximate the target distribution and extracting relevant knowledge from such combination is the purpose of multi-source DA algorithms (e.g.\ \citet{Kim2017, Guo2018, Hoffman2018, Mansour2009, Sebag2019, Zhang2015, Zhao2018}) and is also our main focus in this chapter.

The remainder of the chapter is organized as follows: i) we formalize the problem and provide some useful background by reviewing some important theoretical results and state of the art algorithms (\Secref{sec:chp3_background}); ii) we discuss some exploratory solutions for this problem in the context of sensor networks (\Secref{sec:da_sensors}); and finally iii) we present our own novel algorithm for multi-source domain adaptation (\Secref{sec:modafm}).

\section{Background}
\label{sec:chp3_background}
We start by analyzing the problem of DA from a theoretical perspective and then we overview the main approaches that constitute the state of the art. Although some authors have considered the problem of DA for regression problems (e.g.\ \cite{Cortes2011}, \cite{Zhao2018}), the literature on classification is far more vast. Moreover, many of the results and methods explained in this section can be extended to regression problems with minor modifications. For these reasons, we shall focus our discussion mostly on classification.

\subsection{Theoretical foundation}
\label{sec:da_theory}

\subsubsection{Single source setting}
\label{sec:da_theory_ss}
\citet{BenDavid2010} developed a rigorous yet comprehensive theoretical model for domain adaptation that we summarize here. This formulation enlightens the intrinsic difficulties associated with this task and provides a deep foundation for many of the algorithms we discuss in this chapter and, particularly, to our own approach, presented in \Secref{sec:modafm}.

Before we present and discuss the most important results, let us introduce a few preliminary definitions. A \newterm{domain} $\gD$ is defined by a joint distribution $p_\gD(\rvx, \rvy)$ over input features $\rvx \in \gX$ and target variables $\rvy \in \gY$, where $\gX$ and $\gY$ denote the input and target spaces, respectively. For the domain adaptation task to be well defined, at least two domains must be considered: a \newterm{source} domain $\gS$, with joint distribution denoted by $p_\gS(\rvx, \rvy)$, from which abundant annotated data is usually available, and a \newterm{target} domain $\gT$, with joint distribution $p_\gT(\rvx, \rvy)$, from which scarce or even zero annotated data is available at training time. Following most classical results from statistical learning theory, \citet{BenDavid2010} focused on binary classification, thus $\gY = \{0, 1\}$. Under this setting, it is possible to define a \newterm{labeling function} $f_\gD: \gX \mapsto [0, 1]$ for each domain, given by $f_\gD(\vx) = p_\gD(\ry=1 \mid \vx)$. A \newterm{hypothesis} is any function $h: \gX \mapsto \{0,1\}$ and a set $\gH$ of these functions is called a \newterm{hypothesis class}. The expected absolute difference between $h$ and $f_\gD$ is called the \newterm{risk} (or \newterm{error}) of hypothesis $h$ (with respect to the labeling function $f_\gD$):
\begin{equation}
	\label{eq:risk}
	\epsilon(h,f_\gD) \triangleq \E_{\rvx \sim p_\gD} |h(\rvx) - f_\gD(\rvx)|.
\end{equation}
We use $\epsilon_\gS(h)$ and $\epsilon_\gT(h)$ as shorthands for $\epsilon(h,f_\gS)$ and $\epsilon(h,f_\gT)$ and refer to them as the source and target risks (or errors), respectively. The empirical estimates of these are denoted as $\widehat{\epsilon}_\gS(h)$ and $\widehat{\epsilon}_\gT(h)$, respectively.

Given two domains $\gD$ and $\gD'$ and a hypothesis class $\gH$, the $\gH$-divergence provides a distance measure between the marginal distributions of features in $\gD$ and $\gD'$ (according to $\gH$):
\begin{equation*}
	\label{eq:h_div}
	d_{\gH}(\gD,\gD') \triangleq \sup_{h \in \gH} 2 |\mathrm{Pr}_{\gD}(\1_h) - \mathrm{Pr}_{\gD'}(\1_h)|,
\end{equation*}
where $\1_h \triangleq \{\vx \in \gX: h(\vx)=1\}$ and $\mathrm{Pr}_{\gD}(\1_h)$ is the probability assigned by the distribution $p_\gD(\rvx)$ to the subset $\1_h \subseteq \gX$. As is often the case, when the true underlying marginal distributions are unknown or intractable but finite sets of (unlabeled) samples from both domains are available, an empirical $\gH$-divergence can be constructed by replacing the true probabilities $\mathrm{Pr}_{\gD}(\1_h)$ and $\mathrm{Pr}_{\gD'}(\1_h)$ by the respective empirical estimates. Remarkably, under weak conditions on the hypothesis class, computing this empirical $\gH$-divergence is equivalent to finding the hypothesis in $\gH$ that maximally discriminates between samples of the two domains. This result is enunciated formally in Lemma \ref{lemma:emp_h_div} and, as we shall see later, is exploited by adversarial-based approaches for domain adaptation.
\begin{lemma}
	\label{lemma:emp_h_div}
	(Lemma 2 from \citet{BenDavid2010}) Let $\gH$ be a hypothesis class such that if $h \in \gH$ then $1-h \in \gH$. Given two sets $\widehat{D}$ and $\widehat{D}'$ of $n$ samples each drawn from two domains $D$ and $D'$, the empirical $\gH$-divergence between $D$ and $D'$ is given by:
	\begin{equation}
		\widehat{d}_{\gH}(\gD,\gD') = 2 \left(1 - \min_{h \in \gH} \left[\frac{1}{n} \sum_{\vx: h(\vx)=1} \1_{\vx \in \widehat{\gD}} + \frac{1}{n} \sum_{\vx: h(\vx)=0} \1_{\vx \in \widehat{\gD}'}\right]\right).
	\end{equation}
\end{lemma}
Note that if the two sets $\widehat{\gD}$ and $\widehat{\gD}'$ can be discriminated perfectly by a hypothesis $h \in \gH$ (i.e.\ if there is an $h \in \gH$ such that $h(\vx) = 0$ if $x \in \widehat{\gD}$ and $h(\vx) = 1$ if $x \in \widehat{\gD}'$), then $\widehat{d}_{\gH}(\gD,\gD')$ is maximum and equal to 2.

For a hypothesis class $\gH$, we may define the \newterm{symmetric difference hypothesis class} $\gH \Delta \gH$ as:
\begin{equation}
\label{eq:h_delta_h}
\gH \Delta \gH \triangleq \{l: l(\vx) = h(\vx) \oplus h'(\vx), \; h, h' \in \gH\},
\end{equation}
where $\oplus$ denotes the ``exclusive or" (xor) operation. Combining this definition with \eqref{eq:h_div}, the definition of $\gH \Delta \gH$-divergence, which happens to play a major role in Theorem \ref{thm:da_bound_single_source}, follows immediately. This theorem is the main result in this section as it provides an upper bound for the target risk given the source risk and the $\gH \Delta \gH$-divergence between the source and target domains.
\begin{theorem}
	\label{thm:da_bound_single_source} (Theorem 2 from \citet{BenDavid2010}) Let $\gH$ be a hypothesis class with VC-dimension $d$. Consider $n$ unlabeled samples drawn from each of the two domains $\gS$ (source) and $\gT$ (target). Then, for every $h \in \gH$ and any $\delta \in (0,1)$, with probability at least $1-\delta$ over the choice of samples,
	\begin{equation}
		\label{eq:da_bound_single_source}
		\epsilon_\gT(h) \leq \epsilon_\gS(h) + \frac{1}{2} \widehat{d}_{\gH \Delta \gH}(\gS, \gT) + \lambda + 2\sqrt{\frac{2d\log(2n) + \log(\frac{2}{\delta})}{n}},
	\end{equation}
	where $\lambda \triangleq \min_{h \in \gH} \epsilon_\gS(h) + \epsilon_\gT(h)$.
\end{theorem}
This bound immediately confirms the intuition that a low target error can be achieved by training a classifier to minimize the error in the source domain, provided that the marginal distributions of features are similar (i.e.\ $\widehat{d}_{\gH \Delta \gH}(\gS, \gT)$ is small) and a low error on the combination of the two domains can be achieved (i.e.\ $\lambda$ is also small). A deeper and more complete interpretation of this bound shall be provided later on, when we take into account the fact that, by applying deep neural networks, we can not only construct rich hypothesis classes but also manipulate and learn feature representations. The latter observation suggests that this kind of the classifiers may also have an impact on the $\widehat{d}_{\gH \Delta \gH}(\gS, \gT)$ and $\lambda$ terms in \eqref{eq:da_bound_single_source}, which will indeed be the case.

\subsubsection{Multi-source setting}
\label{sec:da_theory_ms}
So far we have only considered the setting where a single source domain was available. However, in many practical cases, the annotated training dataset consists of a collection of subdatasets, each one belonging to its own domain. Therefore, it makes sense to consider $k$ distinct source domains $\gS_1, \gS_2, \dots, \gS_k$ and, in particular, to see how Theorem \ref{thm:da_bound_single_source} can be generalized to this setting.
\begin{theorem}
	\label{thm:da_bound_multi_source}
	(Theorem 2 from \citet{Zhao2018}) Let $\gH$ be a hypothesis class with VC-dimension $d$. Consider $n$ unlabeled samples drawn from the target domain $\gT$ and $n/k$ annotated samples drawn from each of the $k$ source domains $\gS_1, \gS_2, \dots, \gS_k$. Then, for every $h \in \gH$, any $\valpha \in [0,1]^k: \sum_{j=1}^k \evalpha_i = 1$, and any $\delta \in (0,1)$, with probability at least $1-\delta$ over the choice of samples,
	\begin{equation}
		\label{eq:da_bound_multi_source}
		\epsilon_\gT(h) \leq \sum_{j=1}^k \evalpha_j \left(\widehat{\epsilon}_{\gS_j}(h) + \frac{1}{2} \widehat{d}_{\gH \Delta \gH}(\gS_j, \gT)\right) + \lambda_\valpha + O \left(\sqrt{\frac{1}{n} \left(\log \frac{1}{\delta} +d \log \frac{n}{d} \right)} \right),
	\end{equation}
	where $\lambda_\valpha \triangleq \min_{h \in \gH} \epsilon_\gT(h) + \sum_{j=1}^k \evalpha_j \epsilon_{\gS_j}(h)$.
\end{theorem}
Unsurprisingly, the bound in Theorem \ref{thm:da_bound_multi_source} is essentially a convex combination of the bounds provided by Theorem \ref{thm:da_bound_single_source} for each individual source domain. Thus, the same interpretation applies here. Nonetheless, the source weights $\valpha$ provide an extra degree of freedom that should be taken into account. Depending on how much each source domain differs from the target, it may be beneficial to weight each source domain differently. Adjusting these weights is therefore an extra non-trivial task, exclusive to the multi-source setting, that may have a significant impact in the performance of the domain adaptation algorithm.

\subsection{State of the art}
\label{sec:da_sota}
We now do a brief overview of the most relevant DA algorithms, both in the single source and multi-source settings. 

As we have just seen from a theoretical point of view, the success of the DA task depends on how similar the target domain is to the source(s), which is equivalent to saying that some properties of the underlying distributions must be invariant across domains. Different DA algorithms can therefore be categorized according to the invariance properties they assume.

\subsubsection{Target shift}
\label{sec:target_shift_sota}
\begin{figure}
	\centering
	\begin{tikzpicture}[every loop/.style={},thick,
		main node/.style={circle,draw},font=\sffamily\Large\bfseries]
		
		\node[main node,minimum size=1.5cm] (D) {$\gD$};
		\node[main node,minimum size=1.5cm] (y) [right=1.5cm of D] {$\ry$};
		\node[main node,minimum size=1.5cm] (x) [right=1.5cm of y] {$\rvx$};
		
		\draw[->]
		(D) edge (y)
		(y) edge (x);
		
	\end{tikzpicture}
	\caption{Graphical representation of the target shift setting as a Bayesian network.}
	\label{fig:target_shift}
\end{figure}
In the \newterm{target shift} setting, only the marginal distribution of labels is allowed to vary across domains. A practical example where this assumption may be realistic is when the label $\ry$ represents having or not a certain disease and the input features $\rvx$ are symptoms. It is plausible to assume that the prevalence of the disease may vary over time or across different populations, but the probability of some symptom being present or absent given that one has or not the disease should remain constant. Thus, as represented in \Figref{fig:target_shift}, the joint distribution of any domain $\gD$ is assumed to factorize as $p_\gD(\rvx, \ry) = p(\rvx \mid \ry) p_\gD(\ry)$, where $p(\rvx \mid \ry)$ is domain-invariant. By further assuming that $\mathrm{Supp}(p_\gT(\ry)) \subseteq \mathrm{Supp}(p_\gS(\ry))$, we have:
\begin{align}
	p_\gT(\ry \mid \rvx) &\propto p(\rvx \mid \ry) p_\gT(\ry) \nonumber\\
	&= p(\rvx \mid \ry) p_\gS(\ry) \frac{p_\gT(\ry)}{p_\gS(\ry)} \nonumber\\
	&\propto p_\gS(\ry \mid \rvx) \frac{p_\gT(\ry)}{p_\gS(\ry)}.
\end{align}
Thus, if the class ratios $p_\gT(\ry)/p_\gS(\ry)$ are known, the problem of DA under target shift is solved by learning a probabilistic classifier on the source domain, reweighting it with the class ratios, and then normalizing the class scores. Therefore, the literature for DA under target shift focuses on estimating class ratios when these are unknown and cannot be estimated directly from the training data, due to the absence of labels for the target samples.

An elegant and simple solution to this problem was proposed by \citet{Lipton2018}. Specifically, for any classifier $h: \gX \mapsto \gY$ trained with labeled data from the source domain, the target shift assumption implies that $p_{\gT}(h(\rvx) \mid \ry) = p_{\gS}(h(\rvx) \mid \ry)$ and hence:
\begin{align}
p_{\gT}(h(\rvx)) &= \sum_{\ry} p_{\gT}(h(\rvx) \mid \ry) p_{\gT}(\ry) \nonumber\\
\allowdisplaybreaks
&= \sum_{\ry} p_{\gS}(h(\rvx) \mid \ry) p_{\gT}(\ry) \label{eq:estim_class_dist}\\
\allowdisplaybreaks
&= \sum_{\ry} p_{\gS}(h(\rvx), \ry) \frac{p_{\gT}(\ry)}{p_{\gS}(\ry)}. \label{eq:estim_class_ratio}
\end{align}
Note that $p_{\gS}(h(\rvx) \mid \ry)$, $p_{\gS}(h(\rvx), \ry)$, and $p_{\gS}(\ry)$ can all be estimated from labeled source samples and $p_{\gT}(h(\rvx))$ can be estimated from unlabeled target samples. Thus, one can either use \eqref{eq:estim_class_dist} to estimate $p_{\gT}(\ry)$ or \eqref{eq:estim_class_ratio} to estimate class ratios directly.

Other approaches involve learning class-dependent weights to match the mean conditional features of source data with the mean marginal features of target data in a reproducing kernel Hilbert space (e.g.\  \citet{Iyer2004}, \citet{Zhang2013}), or require density estimation to model $p(\rvx \mid \ry)$ (e.g.\ \citet{Chan2005}, \citet{Storkey2009}).

\subsubsection{Conditional shift}
\label{sec:cond_shift_sota}
\begin{figure}
	\centering
	\begin{tikzpicture}[every loop/.style={},thick,
	main node/.style={circle,draw},font=\sffamily\Large\bfseries]
	
	\node[main node,minimum size=1.5cm] (y) {$\ry$};
	\node[main node,minimum size=1.5cm] (x) [right=1.5cm of y] {$\rvx$};
	\node[main node,minimum size=1.5cm] (D) [right=1.5cm of x] {$\gD$};
	
	\draw[->]
	(y) edge (x)
	(D) edge (x);
	
	\end{tikzpicture}
	\caption{Graphical representation of the conditional shift setting as a Bayesian network.}
	\label{fig:cond_shift}
\end{figure}
In the \newterm{conditional shift} setting, the marginal distribution of labels is constant and the conditional of features given labels may change across domains. This scenario is represented in \Figref{fig:cond_shift}, from which it becomes clear that the joint distribution takes the form $p_{\gD}(\rvx, \ry) = p(\ry) p_{\gD}(\rvx \mid \ry)$, where $p(\ry)$ is domain-invariant. Besides being less realistic than other assumptions, DA under conditional shift is in general an ill-posed problem. Nonetheless, \citet{Zhang2013} show that identifiability of $p_{\gT}(\rvx \mid \ry)$ holds when it is assumed that, for any given $y$, $p_{\gT}(\rvx \mid y)$ only differs from $p_{\gS}(\rvx \mid y)$ in location and scale and derive a kernel-based approach to estimate these parameters.

\subsubsection{Concept shift}
\label{sec:concept_shift_sota}
\begin{figure}
	\centering
	\begin{tikzpicture}[every loop/.style={},thick,
	main node/.style={circle,draw},font=\sffamily\Large\bfseries]
	
	\node[main node,minimum size=1.5cm] (x) {$\rvx$};
	\node[main node,minimum size=1.5cm] (y) [right=1.5cm of x] {$\ry$};
	\node[main node,minimum size=1.5cm] (D) [right=1.5cm of y] {$\gD$};
	
	\draw[->]
	(x) edge (y)
	(D) edge (y);
	
	\end{tikzpicture}
	\caption{Graphical representation of the concept shift setting as a Bayesian network.}
	\label{fig:concept_shift}
\end{figure}
\newterm{Concept shift} refers to the situation where the marginal feature distributions $p(\rvx)$ are constant but the conditional distribution of the target variable $p_{\gD}(\ry \mid \rvx)$ is domain-dependent, thus $p_{\gD}(\rvx, \ry) = p(\rvx)p_{\gD}(\ry \mid \rvx)$, as implied by \Figref{fig:concept_shift}. When the change happens over time, this setting is also known as \newterm{concept drift} (\citet{Webb2018}). The literature on concept drift is vast and focuses mostly on the detection of its occurrence so that the model can be updated using new data. \citet{Gama2014} overview the most popular techniques to address this problem.

\subsubsection{Covariate shift}
\label{sec:cov_shift_sota}
\begin{figure}
	\centering
	\begin{tikzpicture}[every loop/.style={},thick,
	main node/.style={circle,draw},font=\sffamily\Large\bfseries]
	
	\node[main node,minimum size=1.5cm] (D) {$\gD$};
	\node[main node,minimum size=1.5cm] (x) [right=1.5cm of D] {$\rvx$};
	\node[main node,minimum size=1.5cm] (y) [right=1.5cm of x] {$\ry$};
	
	\draw[->]
	(D) edge (x)
	(x) edge (y);
	
	\end{tikzpicture}
	\caption{Graphical representation of the covariate shift setting as a Bayesian network.}
	\label{fig:cov_shift}
\end{figure}
\newterm{Covariate shift} is by far the most common assumption and therefore the most widely addressed setting in the DA literature. As implied by the graphical representation in \Figref{fig:cov_shift}, here the conditional distribution of labels given features is constant and the marginal distribution of features is domain-dependent. Thus, $p_\gD(\rvx, \ry) = p(\ry \mid \rvx) p_\gD(\rvx)$, where $p(\ry \mid \rvx)$ is constant across domains. This assumption might hold for instance in image classification problems where the domain shift is caused by different sensors or lighting conditions.

Since $p_\gT(\ry \mid \rvx) = p_\gS(\ry \mid \rvx)$, infinite labeled data from the source domain and a consistent estimator of this conditional distribution would solve this DA task. However, the former is obviously unrealistic and therefore the problem should be analyzed taking into account that the available data is finite. Let $\ell(\cdot, \cdot)$ be any loss function for the supervised learning problem. The goal is then to find an unbiased estimator of the target loss $\E_{\rvx, \ry \sim p_\gT} \ell(h(\rvx),\ry)$ when no labeled samples from the target domain are available. Following \citet{Sugiyama2007}, if the marginal densities $p_\gS(\rvx)$ and $p_\gT(\rvx)$ are known and assuming $\mathrm{Supp}(p_\gT(\rvx)) \subseteq \mathrm{Supp}(p_\gS(\rvx))$, this estimator can be obtained using \newterm{importance weights} $w(\rvx) \triangleq p_\gT(\rvx)/p_\gS(\rvx)$:
\begin{align}
	\E_{\rvx, \ry \sim p_\gT} \ell(h(\rvx),\ry) &= \sum_{\ry} \int l(h(\rvx),\ry) p_\gT(\rvx, \ry) \d\rvx \nonumber\\
	&= \sum_{\ry} \int \ell(h(\rvx),\ry) p(\ry \mid \rvx) p_\gT(\rvx) \d\rvx \nonumber\\
	&= \sum_{\ry} \int \frac{p_\gT(\rvx)}{p_\gS(\rvx)} \ell(h(\rvx),\ry)  p(\ry \mid \rvx) p_\gS(\rvx) \d\rvx \nonumber\\
	&= \sum_{\ry} \int w(\rvx) \ell(h(\rvx),\ry)  p_\gS(\rvx, \ry) \d\rvx \nonumber\\
	&= \E_{\rvx, \ry \sim p_\gS} w(\rvx) \ell(h(\rvx),\ry).
\end{align}
Hence, $(1/n) \sum_{i=1}^{n} w(\vx_i) \ell(h(\vx_i),y_i)$ is an unbiased estimator of the target loss, constructed using only source data, which can therefore be used as the loss for the supervised learning problem. When the marginal distributions are unknown and the feature space is low-dimensional, kernel density estimation techniques can be employed to estimate them (e.g.\ \citet{Shimodaira2000,Sugiyama2007,Cortes2010}). An alternative that removes the constraint on the support of the marginal target distribution is learning a transformation $T: \gX \mapsto \gX$ such that $p_{\gS}(T(\rvx)) = p_{\gT}(\rvx)$, which can be accomplished using optimal transport theory (\citet{Courty2015}). Later approaches aim to relax the covariate shift assumption by trying to align the joint source and target distributions (\citet{Courty2017}) and extend the same principles to the multi-source setting (\citet{Turrisi2020}).

For high-dimensional data (e.g.\ images), where the marginal distributions are typically unknown and hard to estimate from finite data, deep learning models play an important role by providing a successful tool learn semantically rich low-dimensional feature representations. It is then possible to learn a function $g:\gX \mapsto \gZ$ mapping input data to a new feature space $\gZ$ such that $p_{\gT}(g(\rvx))/p_{\gS}(g(\rvx)) \approx 1$, i.e.\ where the marginal feature distributions of the two domains coincide. This approach has the additional benefit of moving the overlapping support assumption to a lower-dimensional space, where it is less likely to be violated than in the original space (e.g.\ pixel space). In this new feature space the covariate shift has vanished and therefore any classifier $h:\gZ \mapsto \gY$ that achieves low error on the source domain will also perform well in the target. An alternative way of motivating these approaches follows from analyzing again the target risk bound provided in \eqref{eq:da_bound_single_source}. When we presented this bound, we assumed for simplicity that the feature space was fixed and therefore the upper bound would be minimized by minimizing the source risk. However, if the feature space can itself be optimized, the term $\widehat{d}_{\gH \Delta \gH}(\gS, \gT)$ can be minimized by finding a feature space where the source and target marginal distributions coincide. This idea has been exploited extensively in recent years, either by matching the distributions using maximum mean discrepancy (e.g.\ \citet{Long2015,Guo2018}) or, in most cases, using an adversarial neural network (e.g.\ \citet{Zhao2018,Ganin2015,Pei2018,Sebag2019}).

Adversarial-based DA was originally introduced by \citet{Ganin2015} and results from the observation that 
computing $\widehat{d}_{\gH \Delta \gH}(\gS, \gT)$ is equivalent to finding a classifier that maximally discriminates between samples of the source and target domains (Lemma \ref{lemma:emp_h_div}). Intuitively, if no classifier exists that can distinguish between source and target features, then the distributions of these two must coincide. Thus, if we have access to sets $\widehat{\gS}$ and $\widehat{\gT}$ of labeled samples from the source domain and unlabeled samples from the target, respectively, we can train a feature extractor network $g:\gX \mapsto \gZ$, a classifier $h:\gZ \mapsto \gY$, and a domain discriminator $d:\gZ \mapsto \{0,1\}$ to solve the following minimax problem\footnote{This objective is merely formal since the 0-1 loss is non-smooth and intractable. In practice, the usual classification losses are used instead.}:
\begin{equation}
	\label{eq:dann_obj}
	\min_{g,h} \max_d \quad \widehat{\epsilon}_\gS(h \circ g) + 1 - \left(\frac{1}{n} \sum_{\vx: d(g(\vx))=1} \1_{\vx \in \widehat{\gS}} + \frac{1}{n} \sum_{\vx: d(g(\vx))=0} \1_{\vx \in \widehat{\gT}}\right),
\end{equation}
where $\circ$ denotes function composition. Several variations to this idea have been proposed so far, aiming to extend it to the multi-source setting (\citet{Zhao2018}), or beyond the covariate shift assumption (\citet{Pei2018}), or both (\citet{Sebag2019}).

\subsubsection{Invariance of causal mechanisms}
\label{sec:causal_da_sota}
The settings we have discussed so far consider all features $\rvx$ as atomic and hence do not take into account how different features interact to produce the target variable $\ry$.  Other approaches drop this limitation by decomposing the feature vector into individual features $\rx_1,\rx_2,\dots,\rx_m$, taking into account the structure of the causal Bayesian network governing the data generating process, and using causal inference tools to identify the target distribution. These methods assume that the flow of cause and effect cannot be reversed by domain shift and therefore changes in distribution are due to different interventions in the same causal graph $\gG$ (e.g.\ presence of additional exogenous variables inducing non-causal associations between features and the target variable). \citet{Bareinboim2016} assume $\gG$ is known and all interventions are perfect (i.e.\ all interventions consist of edge removal operations) and derive conditions for identifiability of $p_\gT(\ry \mid \cdots)$ given $\gG$ and $p_\gS(\rvx, \ry)$. \citet{Rojas2018} and \citet{Magliacane2018} relax the covariate shift setting by assuming that there exists a strict subset $\bar{\rvx} \subset \rvx$ such that $p_\gD(\ry \mid \bar{\rvx})$ is domain-invariant and propose algorithms to infer $\bar{\rvx}$ given data from multiple source domains.

Despite being (arguably) more trustworthy than purely data-driven approaches, cau-\allowbreak sality-based methods still struggle to be applied in practice. First of all, they depend to some extent on $\gG$ being given. In many applications, domain knowledge is insufficient to build such a graph. Moreover, causal discovery algorithms, which aim to learn the structure of the graph from data, are computationally expensive and, given observational data, can only recover $\gG$ up to its Markov equivalence class, at least when no parametric assumptions are made  (\citet{Peters2014}). Furthermore, these methods are unsuitable to be applied to image data as no meaningful causal reasoning can be built in pixel space and even deep neural networks are still incapable of finding suitable representations for this goal (\citet{Scholkopf2021}).

\section{Adversarial domain adaptation for object counting in videos}
\label{sec:da_sensors}

\subsection{Motivation}
As different sensors are added to and excluded from a network, we should take into account the fact that the sensors used at training time are different from the ones where the model will make predictions. Since domain shifts between different sensors on a sensor network are usually substantial, it is imperative that robust domain adaptation methods are developed that take into account the constraints of the sensor network.

There is a lack of domain adaptation methods focusing on how to handle the temporal component of data. \citet{Chen2019} proposed an algorithm called Temporal Attentive Alignment for implementing DA in video datasets that explicitly attends to temporal dynamics and \citet{Liu2014} proposed a spatio-temporal DA model named TrCbrBoost for classifying land use. It should be noted, though, that both of these works only deal with a single-source-single-target setting, which is simpler than the multi-source case present when dealing with sensor networks.

For dealing with a multi-source setting, adversarial approaches have proven successful. \citet{Zhao2018} introduced an algorithm called multi-source domain adversarial networks (MDAN) that makes use of $k$ domain discriminators that aim to distinguish between the target and the $k$ source domains. MDAN showed superior performance when compared to other state of the art methods on the task of counting vehicles in images obtained from city cameras videos. Given the positive results obtained, and given the fact that MDAN does not consider the temporal component of the video frames, we consider it is worthy to investigate the adaptation of this model so that it can receive a temporal sequence as an input.

The setting where sensors correspond to video cameras is especially interesting since video data is very high-dimensional. Moreover, the fact that different cameras are located in different places, and therefore have distinct points of view, increases the domain shift and therefore makes this task even more challenging.

Here, we shall explore how to adapt the MDAN model so that both of its adversarial networks are LSTM-based. We decided to go with this type of network since it has already shown promising results in our task: \citet{Zhang2017} introduced an LSTM network architecture for counting vehicles in images obtained from city cameras and reported an improvement of the mean absolute error when compared to other state of the art methods.

\subsection{MDAN: Multi-source domain adversarial networks}
\label{sec:da_sensors_mdan}
We now review the MDAN model introduced by \citet{Zhao2018}. This model is motivated by the target risk bound provided in Theorem \ref{thm:da_bound_multi_source} and is an extension to the multi-source setting of the single source model by \citet{Ganin2015}. Specifically, the following formal objective is considered:
\begin{equation}
	\min_{g,h} \max_{j \in \{1,\cdots,k\}} \quad \widehat{\epsilon}_{\gS_j}(h \circ g) + \frac{1}{2} \widehat{d}_{\gH \Delta \gH}(\gS^g_j, \gT^g),
\end{equation}
where $g: \gX \mapsto \gZ$ and $h: \gZ \mapsto \gY$ are, as before, the feature extractor and the classifier networks and $\gS^g_j$ and $\gT^g$ are, respectively, the $j$-th source domain and the target domain representations in the new feature space $\gZ$ (i.e.\ $p_{\gD^g}(\rvx) \triangleq p_\gD(g(\rvx))$ for any domain $\gD$). Here, the empirical $\gH \Delta \gH$-divergence between $\gS^g_j$ and $\gT^g$ is also implemented with an adversarial domain discriminator $d_j:\gZ \mapsto \{0,1\}$ aiming to discriminate between samples of the two domains. Thus, the model comprises $k$ domain discriminator networks, i.e.\ one for each source domain. This objective is therefore identical to \eqref{eq:dann_obj} with the only difference that, since here there are multiple source domains, the model is optimized for the hardest source domain at each training iteration. In this formulation, $\valpha$ in \eqref{eq:da_bound_multi_source} is a one-hot vector whose active component corresponds to the hardest source domain. Because the bound holds for any convex combination of source domains, the authors also explore a soft-max version of this problem, where smaller positive weights are assigned to the easier source domains:
\begin{equation}
\min_{g,h} \quad \frac{1}{\gamma} \log \sum_{j=1}^{k} \exp \left( \gamma( \widehat{\epsilon}_{\gS_j}(h \circ g) + \frac{1}{2} \widehat{d}_{\gH \Delta \gH}(\gS^g_j, \gT^g)) \right).
\end{equation}
Here, $\gamma > 0$ is a hyperparameter controlling the softness of the max operation ($\gamma \to \infty$ corresponds to the hard-max). In our experiments, we will also evaluate the scenario where the weights $\valpha$ are equal for all domains, i.e.\ where the multi-domain loss consists of the simple average of the losses across source domains.

\subsubsection{The gradient reversal layer}
\label{sec:da_sensors_grad_rev}
Adversarial DA algorithms, of which MDAN is a particular case, all aim to solve some variant of the following minimax problem:
\begin{equation}
	\min_{\vtheta_g, \vtheta_h} \max_{\vtheta_d} \quad \left \lbrace L(\vtheta_g, \vtheta_h, \vtheta_d) =  L_{\text{task}}(\vtheta_g, \vtheta_h) - \lambda_d L_{\text{disc}}(\vtheta_g, \vtheta_d) \right \rbrace,
\end{equation}
where $L_{\text{task}}$ is the supervised loss for the desired task, $L_{\text{disc}}$ is the classification loss for the domain discrimination task, $\vtheta_g$, $\vtheta_h$, and $\vtheta_d$ are the parameters of the feature extractor, task classifier, and domain discriminator networks, respectively, and $\lambda_d > 0$ is a hyperparameter. This is a treatable surrogate of objective \plaineqref{eq:dann_obj}.

Solving this problem then consists in finding a saddle point of this loss function. Using automatic differentiation libraries (e.g.\ PyTorch or TensorFlow), the naive solution would involve declaring two optimizers, one for parameters $\vtheta_g$ and $\vtheta_h$ and another for $\vtheta_d$, and then performing gradient descent with the former and gradient ascent with the latter:
\begin{align}
	&\vtheta_g \leftarrow \vtheta_g - \rho \left(\nabla_{\vtheta_g}L_{\text{task}} - \lambda_d \nabla_{\vtheta_g} L_{\text{disc}}\right), \label{eq:grad_feature_extractor}\\
	&\vtheta_h \leftarrow \vtheta_h - \rho \nabla_{\vtheta_h}L_{\text{task}}, \label{eq:grad_task_class}\\
	&\vtheta_d \leftarrow \vtheta_d + \rho \left(-\lambda_d \nabla_{\vtheta_d}L_{\text{disc}}\right), \label{eq:grad_discriminator}
\end{align}
where $\rho>0$ is the learning rate. This implies an extra computational burden because gradients need to be backpropagated through the discriminator network twice, one for computing $\nabla_{\vtheta_d} L_{\text{disc}}$ and another for computing $\nabla_{\vtheta_g} L_{\text{disc}}$.

The gradient reversal layer (\citet{Ganin2015}) is an ingenious solution to this problem. This layer is a pseudo-function $r$ that behaves as the identify in the forward pass but inverts the sign of the gradient in the backward, i.e.:
\begin{equation}
	r(\vx) \triangleq \vx, \quad \frac{\partial r}{\partial \vx} \triangleq -I.
\end{equation}
By placing it in between the feature extractor $g$ and the domain discriminator $d$, the gradient $\nabla_{\vtheta_g} L_{\text{disc}}$ will come with its sign inverted. Thus, performing gradient descent over all parameters of
\begin{equation}
	L_{\text{task}}(\vtheta_g, \vtheta_h) + \lambda_d L_{\text{disc}}(\vtheta_g, \vtheta_d),
\end{equation}
yields exactly update equations \plaineqref{eq:grad_feature_extractor}, \plaineqref{eq:grad_task_class}, and \plaineqref{eq:grad_discriminator}.

\subsection{FCN-rLSTM: Spatio-temporal deep neural network for object counting}
\label{sec:da_sensors_fcn_rltsm}

\citet{Zhang2017} proposed FCN-rLSTM, a deep neural network architecture for counting vehicles in low-quality videos captured by city cameras that will constitute the backbone of our models. 

Although each video frame should contain all the information required to identify the number of vehicles in it, issues with the quality of the collected data can make vehicle counting a difficult problem, namely low resolution, vehicle occlusion, and different vehicle scales, particularly noticeable when the camera is too close to the road. Thus, assuming that the frame rate is sufficiently large when compared to the vehicles speed, leveraging information from the previous frames should help improving the accuracy of the prediction for the current frame. For this reason, FCN-rLSTM combines a fully convolutional network with a recurrent module, which preserves memory from the previous frames in LSTM cells. This is a density-based estimation method, being able to deal well with low frame rates, low resolutions, and vehicle occlusions, but having difficulty in accounting for different vehicle scales.

\begin{figure}
	\centering
	\includegraphics[width=0.9\linewidth]{ChapterThree/fcn_rlstm.png}
	\caption{Architecture of the FCN-rLSTM model (reprinted from \citet{Zhang2017}).}
	\label{fig:fcn_rlstm}
\end{figure}

\Figref{fig:fcn_rlstm} shows the full architecture of this model, from which it can be observed that the convolutional part outputs a density map $\widehat{\mD}$. The density maps are normalized so that the sum of the pixels corresponding to each vehicle sum up to 1 and, therefore, the sum of all pixels in the density map sup to the total number of vehicles in the frame. Thus, the final predicted count $\widehat{y}^{(t)}$ is the result of this sum plus a residual provided by a recurrent neural network, which aims to correct the predicted count by leveraging information from the previous frames.

Training this model implies that each input frame $\mX^{(t)}$ is annotated with the corresponding ground-truth density map $\mD^{(t)}$ and vehicle count $y^{(t)}$. The loss function is defined as:
\begin{equation}
	L(\vtheta) = \frac{1}{n} \sum_{i=1}^{n} ||\widehat{\mD}^{(t)}_i - \mD^{(t)}_i||^2_F + \frac{\lambda_c}{n} \sum_{i=1}^{n} ||\widehat{y}^{(t)}_i - y^{(t)}_i||^2,
\end{equation}
where $||\cdot||_F$ is the Frobenius norm, $\lambda_c > 0$ is a hyperparameter controlling the relative weight of the vehicle counting loss, and the dependency of $\widehat{\mD}^{(t)}_i$ and $\hat{y}^{(t)}_i$ on the network parameters $\vtheta$ is omitted to ease the notation.

\subsection{Combining MDAN and FCN-rLSTM}
\label{sec:mdan_fcn_rlstm}
We now explore several possibilities to combine MDAN and FCN-rLSTM into a single model capable of accurately counting vehicles in images from a target camera, provided that at training time we only have access to annotated data from other cameras and unlabeled data from the target.

\subsubsection{Non-temporal model}
The non-temporal model uses a sub-network in the FCN-rLSTM model as its backbone. It consists in a simplification of this, by not using LSTMs or making any other consideration on the temporal or sequential nature of the data. Figure \ref{fig:non_temporal_model} shows the architecture of the non-temporal model.

\begin{figure}[!ht]
	\centering
	\includegraphics[width=1.0\textwidth]{ChapterThree/non_temporal.png}
	\caption{Non-temporal model. Reprinted from \citet{ThesisFrancisco}.}
	\label{fig:non_temporal_model}
\end{figure}

The component F-HAC in that figure corresponds to all layers of the FCN-rLSTM up to the hyper-atrous combination. It is used as a feature extractor, whereas the rest of the convolutional layers are used for the object counting task. The $k$ domain discriminators consist of two fully connected layers which are preceded by a gradient reversal layer. 

This model will be our baseline as we are primarily interested in merging the benefits of DA techniques and sequential modeling.

\subsubsection{SingleLSTM model}
The SingleLSTM model uses the whole FCN-rLSTM model for the desired regression task, but the domain discriminators are still non-sequential, as shown in \Figref{fig:temporal_regress_model}. Thus, in this model, the domain discrimination task only takes into account the domain-specific information provided by each frame individually and does not account for the domain-specific temporal dynamics that may exist.

\begin{figure}[h!]
	\centering
	\includegraphics[width=1.0\textwidth]{ChapterThree/temporal_regress.png}
	\caption{Temporal regression model. Reprinted from \citet{ThesisFrancisco}.}
	\label{fig:temporal_regress_model}
\end{figure}

\subsubsection{DoubleLSTM model}
The DoubleLSTM model overcomes the limitations of the temporal regression model by incorporating three LSTM layers in each domain discriminator. These aim to learn the domain-specific temporal dynamics that might be helpful for the discrimination task. The schematic is in \Figref{fig:double_temporal_model}.

\begin{figure}[!ht]
	\centering
	\includegraphics[width=1.0\textwidth]{ChapterThree/double_temporal.png}
	\caption{Double-Temporal model. Reprinted from \citet{ThesisFrancisco}.}
	\label{fig:double_temporal_model}
\end{figure}

\subsubsection{CommonLSTM model}
An alternative to the DoubleLSTM model is to extract temporal features that are common to the desired object counting task and to the domain discrimination task. This is accomplished by the CommonLSTM model, which pushes the domain discriminators after the LSTMs and just before the final fully connected layer, as shown in \Figref{fig:common_temporal_model}.

\begin{figure}[!ht]
	\centering
	\includegraphics[width=1.0\textwidth]{ChapterThree/common_temporal.png}
	\caption{Common-Temporal model. Reprinted from \citet{ThesisFrancisco}.}
	\label{fig:common_temporal_model}
\end{figure}

This model is fundamentally different from all previous ones since here the feature space where domain-invariance is promoted happens much later in the network. Specifically, the density maps $\widehat{D}$ are a few layers earlier, so they should not be very much affected by the domain-invariance constraint. This might have a beneficial effect on the performance since density maps are defined by the positions in the image where vehicles appear. Since these positions depend on the shape of the street that each camera is capturing, domain-invariant density maps will almost surely be inaccurate.

\subsubsection{Overview}

All the proposed models have specific strengths and weaknesses that would make them suitable for certain scenarios and unlikely to show a good performance in others. Here, we anticipate a few of those scenarios.

If the video frame rate is low compared to the objects speed, the number of objects in a given frame is not a good predictor for the number of objects in a subsequent frame. In this setting, the non-temporal model is ideal, as it does not make any temporal consideration. In this case, using a temporal model would probably just upset the training process.

If the frame rate is sufficiently high and the temporal dynamics in the target domain are close to the dynamics in the sources, the SingleLSTM model is likely the best choice. By using an LSTM for the task executor but none for the domain discriminators, it will be able to make small adjustments in the predicted object count and avoid the unnecessary computational cost introduced by having a sequential model in the domain discriminator.

When there is a strong correlation in the object count in consecutive video frames and the dynamics in the target domain are dissimilar to the sources, it may be beneficial to employ sequential models in both the task executor and domain discriminators. Thus, DoubleLSTM and CommonLSTM models are likely to outperform the remaining. Their approach differs, as DoubleLSTM model uses an LSTM network for the task executor and another one for each domain discriminator, whereas CommonLSTM includes an LSTM network in the feature extractor. As the common-temporal model will not enforce similarity between the predicted density maps as much as the double-temporal version, it is probably the best choice when the density maps of the target domain differ significantly from the sources.

\subsection{Experiments}

\subsubsection{Experimental protocol}

We will run experiments with networks FCN-HA and FCN-rLSTM, proposed by \citet{Zhang2017} in paper "FCN-rLSTM: Deep Spatio-Temporal Neural Networks for
Vehicle Counting in City Cameras", described in detail in section \ref{sec:fcn_rlstm}. The FCN-HA does not consider the temporal nature of data, whereas the FCN-rLSTM does, and neither of them . Additionally, we will run experiments with the models presented in \Secref{sec:mdan_fcn_rlstm}.

In every experiment, assume we have $k+1$ domains $D_1, D_2,...,D_{k+1}$. In a domain adaptation scenario, we do $k+1$ runs, so that in run number $t$, domain $D_t$ will be chosen as the target domain and all the others will be source domains.

For every experiment, we have computed results in both unsupervised and semi-supervised settings, described below:

\begin{itemize}
	\item \textbf{Unsupervised:} In this case, we do not have a validation dataset, and, for each run $t$, we calculate the testing results with the model we obtained at the end of the training epochs, for all the samples extracted from domain $D_t$.
	\item \textbf{Semi-supervised:} For semi-supervised results, we have a validation dataset, that corresponds to $30\%$ of the samples extracted from target $D_t$. We use those samples to select the best epoch obtained throughout training. The model obtained in that epoch will be used to test the remaining $70\%$ of the samples in $D_t$.
\end{itemize}

For each dataset, we ran a total of $5$ experiments for the DA models, where we varied the value of hyperparameter $\lambda_d$ in the range $[10^{-5}, 10^{-1}]$. Recall that $\lambda_d$ controls the weight to give to the domain discrimination loss, relative to the task execution loss.

In all experiments, we train the model for $50$ epochs, using Adam optimizer (\citet{Kingma2014}) with a learning rate of $10^{-4}$. The adopted evaluation metric is the Mean Absolute Error (MAE) between the predicted object count and the ground truth for each frame.

\subsubsection{WebCamT dataset}

WebCamT (\citet{Zhang2017b}) is a vehicle counting dataset that contains city camera videos, taken from a stationary camera in different points of the city of New York. All videos are in color, with dimensions $240 \times 352$, at a $1$ frame per second rate. Every frame in the dataset has a ground truth file with annotations that indicate the center of each vehicle and also its bounding box. 

There are a total of $14$ cameras, that cover multiple scenes, camera perspectives, congestion states  and weather conditions. We chose a total of $4$ cameras from those $14$ to correspond to our domains. Each of those $4$ cameras had a number of videos, from which we selected $1000$ frames. The frames were selected consecutively, so that if frames $f_1$ and $f_2$ from the same video $V$ were selected, then every frame between $f_1$ and $f_2$ in video $V$ was also selected.

Figures \ref{fig:webcamt_511}-\ref{fig:webcamt_846} show examples of frames in each one of the four domains. Table \ref{tab:webcamt_domains} shows the mean and standard deviation for the number of vehicles in a frame, for each domain. As it is possible to observe, the mean number of vehicles in each frame differs significantly across domains, being more than three times larger in domain \textit{691} than in domain \textit{846}. Hence, there is significant target shift in this dataset and, consequently, the covariate shift assumption does not hold.

\begin{figure}[!ht]
	\centering
	\begin{minipage}[b]{0.4\textwidth}
		\includegraphics[width=\textwidth]{ChapterThree/511_example.png}
		\caption{Domain \textit{511} from WebCamT dataset (\citet{Zhang2017b}).}
		\label{fig:webcamt_511}
	\end{minipage}
	\hfill
	\begin{minipage}[b]{0.4\textwidth}
		\includegraphics[width=\textwidth]{ChapterThree/551_example.png}
		\caption{Domain \textit{551} from WebCamT dataset (\citet{Zhang2017b}).}
		\label{fig:webcamt_551}
	\end{minipage} \\
	\vspace{1cm}
	\begin{minipage}[b]{0.4\textwidth}
		\includegraphics[width=\textwidth]{ChapterThree/691_example.png}
		\caption{Domain \textit{691} from WebCamT dataset (\citet{Zhang2017b}).}
		\label{fig:webcamt_691}
	\end{minipage} 
	\hfill
	\begin{minipage}[b]{0.4\textwidth}
		\includegraphics[width=\textwidth]{ChapterThree/846_example.png}
		\caption{Domain \textit{846} from WebCamT dataset (\citet{Zhang2017b}).}
		\label{fig:webcamt_846}
	\end{minipage}
\end{figure}

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|}
		\hline
		\textbf{Domain} & \textbf{Mean} & \textbf{Std}  \\
		\hline
		\textit{511} & 12.039 & 6.32 \\
		\hline
		\textit{551} & 18.362 & 4.21 \\
		\hline
		\textit{691} & 25.470 & 10.738 \\
		\hline
		\textit{846} & 6.873 & 2.477 \\
		\hline
	\end{tabular}
	\caption{Mean number of vehicles and respective standard deviation for each domain in the WebCamT dataset.}
	\label{tab:webcamt_domains}
\end{table}

After extracting each frame from the videos, we computed its density map, by placing a $4\times4$ Gaussian kernel with sum $1$ on the center of each car. We then had to resize the frames and density to maps to size $120\times 176$ so that we could deal with speed and memory constraints. Figure \ref{fig:webcamt_density_map} shows an example of a density map in a resized frame, where the Gaussian kernel around each car is shown in red.

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.75\textwidth]{ChapterThree/webcamt_density_map.png}   
	\caption{Example density map for WebCamT dataset}
	\label{fig:webcamt_density_map}
\end{figure}

\subsection{Choice of optimization problem}

As in each run of the experiment there are three different source domains, this is a multi-source scenario. As such, there are three possible optimization problem formulations for our DA models to solve, namely hard-max, soft-max, and average, as described in \secref{sec:da_sensors_mdan}. Table \ref{table:optimization_experiments} shows results for each of our models on these formulations, evaluated in an unsupervised setting. These suggest that averaging performs consistently better than the other two approaches in this dataset. This is somewhat intuitive: given the wide range of values for the mean number of vehicles in each frame across domains, it would be likely for one source domain to show a significantly higher loss than the others. If we use any of the other two optimization problems, our models would dedicate an outweighed importance to the hardest source domain, disregarding the other domains. For this reason, we shall adopt the averaging formulation in all subsequent experiments.

\begin{table}[!ht]
	\centering
	\begin{tabular}{| c | c | c | c |}
		\cline{2-4}
		\multicolumn{1}{c|}{} & \multicolumn{3}{c|}{Optimization Problem} \\
		\cline{1-4}
		Model & Hard-max & Soft-max & Average\\
		\hline
		Non-temporal & 18.146 & 11.160 & 9.846  \\
		\hline 
		SingleLSTM & 10.543 & 9.326 & 10.532  \\
		\hline
		DoubleLSTM & 9.589 & 7.731 & 6.148 \\
		\hline
		CommonLSTM & 9.847 & 12.069 & 8.146 \\
		\hline
	\end{tabular}
	\caption{Comparison of different optimization problems. The table indicates the Avg. MAE Count across domains. The experiments were run with $\lambda_d=10^{-3}$. }
	\label{table:optimization_experiments}
\end{table}

\subsection{Unsupervised Setting}

Table \ref{table:webcamt_unsupervised_results} shows the results in the unsupervised setting. For the domain adaptation models (non-temporal, temporal regression, double-temporal and common-temporal), columns \textit{511}, \textit{551}, \textit{691} and \textit{846} indicate the best MAE Count obtained for the respective domain in the $5$ experiments with the different values of $\lambda_d$ indicated before. Column Avg indicates the best average of the MAE Count across domains \textit{511}, \textit{551}, \textit{691} and \textit{846} in the $5$ experiments. That is, for each experiment, we compute the average MAE Count across the $4$ domains. We then select the best of the computed average MAE Count.

\begin{table}[!ht]
	\centering
	\begin{tabular}{| c | c | c | c | c | c |}
		\cline{2-6}
		\multicolumn{1}{c|}{} & \multicolumn{5}{c|}{Domain} \\
		\cline{1-6}
		Model & \textit{511} & \textit{551} & \textit{691} & \textit{846} & Avg\\
		\hline
		FCN-HA & \textbf{5.006} & \textbf{2.577} & 17.224 & 4.674 & 7.370\\
		\hline
		FCN-rLSTM & 6.26 & 8.789 & 13.632 & 6.305 & 8.746\\
		\hline
		Non-temporal & 9.629 & 3.497 & 18.271 & 5.581 & 9.846 \\
		\hline 
		SingleLSTM & 6.579 & 5.100 & 15.264  & 9.553 & 10.532 \\
		\hline
		DoubleLSTM & 5.013 & 4.576 & 10.973 & \textbf{3.029} & \textbf{6.148}\\
		\hline
		CommonLSTM & 6.106 & 5.552 & \textbf{10.508} & 3.564 & 8.146 \\
		\hline
	\end{tabular}
	\caption{MAE Count by domain. For each domain, the best MAE obtained from experiments run with different values of $\lambda_d$ is shown. Column Avg indicates the best average of the MAE Count for domains \textit{511}, \textit{551}, \textit{691} and \textit{846} in experiments run with different values of $\lambda_d$.}
	\label{table:webcamt_unsupervised_results}
\end{table}

For the average of the MAE Count across domains, the DoubleLSTM model showed the best results with a MAE of $6.148$, followed by the FCN-HA with a MAE of $7.370$. In this dataset, the temporal models did not seem to perform particularly better than the non-temporal ones. Even though the double-temporal showed the best results, the second best was the FCN-HA, a model that does not make any temporal consideration. We also could not verify a marked difference in the average MAE count of the DA and non-DA methods. These observations ascertain that it is not enough to apply domain adaptation or consider the temporal nature of data to obtain good results. Thus, the careful design of models and its integration with the two mentioned techniques is essential. 

When it comes to the accuracy of models across different domains, we find that domain \textit{691} has the worst results, since it has the most dissimilar vehicle count distribution (highest mean and also highest standard deviation), which cannot be matched by any mixture of the source vehicle count distributions. It is observable that the performance of models across different domains is not consistent. For example, the FCN-HA model shows the best results for domains \textit{511} and \textit{551}, but the second worst result for domain \textit{691}. 

We find that the model with the most balanced performance across domains was the DoubleLSTM as its MAE Count in a given model was either the best or the second best. This coupled with the fact that the DoubleLSTM was also the model with the best average MAE count allows us to conclude that this method was the best-performing in the WebCamT dataset.

\Figref{fig:webcamt_unsupervised_graph} shows the average MAE count across domains for every DA model experiment, run with a different value of $\lambda_d$.

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.85\textwidth]{ChapterThree/webcamt_unsupervised.png}   
	\caption{Avg. MAE Count across domains for every $\lambda_d$ (unsupervised setting).}
	\label{fig:webcamt_unsupervised_graph}
\end{figure}

This graph confirms that the model DoubleLSTM was the best-performing in the WebCamT dataset. The SingleLSTM, on the other hand, showed the worst results, even when comparing it against Simple Model, a non-temporal method. It is also noticeable that model DoubleLSTM has the best accuracy for the intermediate value of $\lambda_d=10^{-3}$. On the other hand, CommonLSTM shows a tendency to improve the MAE Count as the $\lambda_d$ decreases.

\subsection{Semi-supervised Setting}

Table \ref{table:webcamt_semi-supervised_results} shows the results in the semi-supervised setting. Like in the table \ref{table:webcamt_unsupervised_results}, for the domain adaptation models (Simple, SingleLSTM, DoubleLSTM and CommonLSTM), columns \textit{511}, \textit{551}, \textit{691} and \textit{846} indicate the best MAE Count obtained in the $5$ experiments with the different values of $\lambda_d$ indicated before. Column Avg indicates the best average of the MAE Count for domains \textit{511}, \textit{551}, \textit{691} and \textit{846} in the 5 experiments.

\begin{table}[!ht]
	\centering
	\begin{tabular}{| c | c | c | c | c | c |}
		\cline{2-6}
		\multicolumn{1}{c|}{} & \multicolumn{5}{c|}{Domain} \\
		\cline{1-6}
		Model & \textit{511} & \textit{551} & \textit{691} & \textit{846} & Avg\\
		\hline
		FCN-HA & \textbf{2.050} & \textbf{2.589} & 6.560 & 2.394 & \textbf{3.398} \\
		\hline
		FCN-rLSTM & 5.400 & 3.486 & 9.153 & 3.537 &  5.394 \\
		\hline
		Simple & 3.112 & 3.565 & 10.964 & 2.049 & 5.035 \\
		\hline 
		SingleLSTM & 4.239 & 4.393 & 7.032 & \textbf{1.520} & 4.327 \\
		\hline
		DoubleLSTM & 4.223 & 4.552 & \textbf{6.456} & 1.583 & 4.271 \\ 
		\hline
		CommonLSTM & 4.227 & 4.543 & 8.668 & 1.634 & 4.984 \\
		\hline
	\end{tabular}
	\caption{MAE Count by domain. For each domain, the best MAE obtained from experiments run with different values of $\lambda_d$ is shown. Column Avg indicates the best average of the MAE Count for domains \textit{511}, \textit{551}, \textit{691} and \textit{846} in the experiments run with different values of $\lambda_d$.}
	\label{table:webcamt_semi-supervised_results}
\end{table}

There is a noticeable difference between the semi-supervised results and the unsupervised ones, with the former being significantly better that the latter. As the experiments we ran with the WebCamT had more data and more domains, that led to a reduction in the instability of the models, which caused the difference in accuracy between the two settings to not be as wide.

Like in the unsupervised results, we were not able to notice a significant difference between the performance of the temporal methods and the non-temporal ones. As we have also verified before, the DA models do not show a marked improvement over the non-DA models for the WebCamT dataset. In fact, in this case, it was a non-temporal, non-DA model, the FCN-HA, that showed the best average MAE count.

\Figref{fig:webcamt_semi-supervised_graph} shows the average MAE count across domains for every DA model experiment, run with a different value of $\lambda_d$.

\begin{figure}[!ht]
	\centering
	\includegraphics[width=0.85\textwidth]{ChapterThree/webcamt_semisupervised.png}   
	\caption{Avg. MAE Count across domains for every $\lambda_d$ (semi-supervised setting).}
	\label{fig:webcamt_semi-supervised_graph}
\end{figure}

The DoubleLSTM had, in general, the best average MAE count in the semi-supervised graph, similar to what it was verified in the unsupervised case. The Simple Model was the worst, unlike in the unsupervised setting, where it was the SingleLSTM that showed the worst results.

The average MAE count across different values of $\lambda_d$ is considerably more stable in the semi-supervised results than in the unsupervised ones. We were not able to notice an improvement in the performance of the CommonLSTM as $\lambda_d$ decreased, just like we were not able observe a notorious lower average MAE count in the DoubleLSTM model, for $\lambda_d=10^{-3}$. Because the unsupervised results are more unstable, they are also more sensible  to variations of the value of $\lambda_d$ that are not discernible in the semi-supervised graph.

\subsubsection{Discussion}

It stands out that models DoubleLSTM and CommonLSTM showed a better performance than the state-of-art method for counting objects FCN-rLSTM in every dataset and in every setting (unsupervised and semi-supervised). In particular, when it comes to the average MAE count in the unsupervised results, the DoubleLSTM model showed an average improvement of $27\%$ , whereas the CommonLSTM model showed an average improvement of $17\%$, when compared against the FCN-rLSTM. As such, these results underline the contribution this dissertation made to the problem of adversarial domain adaptation in sensor networks.

Models Simple and SingleLSTM, on the other hand, had a very unsatisfactory performance, by not showing better results than methods FCN-rLSTM and FCN-HA, even though they leveraged the power of domain adaptation and, in the case of SingleLSTM, the power of LSTMs to make temporal considerations about the nature of data. When it comes to the Non-temporal model, it appears the reason for its low accuracy is the fact that, without the power of LSTMs, applying domain adaptation to the FCN-HA just disturbs the training process. As for the SingleLSTM, having a too big of a difference in the complexity of its task executor and its domain discriminator is the most likely cause for its failure to show improvements relative to the state-of-art methods.

We have thus verified that integrating domain adaptation with a method does not automatically guarantee better results. Careful considerations on how to divide the previous method between feature extractor and task executor should be made, just like careful deliberations on the domain discriminator design.

It should also be noticed that the results showed an inconsistency in the performance of models across domains. That is, whereas a model performed better in one domain, another model performed better in another. Hence, when applying a model for counting objects in a real world scenario, one should ponder what model to use depending on the characteristics of the particular target domain.

Please refer to \citet{ThesisFrancisco} for an extended discussion and further experimental results.