% Encoding: UTF-8

@Comment{jabref-meta: databaseType:bibtex;}

@book{Goodfellow2016,
	title={Deep Learning},
	author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
	publisher={MIT Press},
	note={\url{http://www.deeplearningbook.org}},
	year={2016}
}


@article{Hinton06,
	author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
	journal = {Neural Computation},
	pages = {1527--1554},
	title = {A Fast Learning Algorithm for Deep Belief Nets},
	volume = {18},
	year = {2006}
}


@article{Baron,
	author    = {Dror Baron and
	Marco F. Duarte and
	Michael B. Wakin and
	Shriram Sarvotham and
	Richard G. Baraniuk},
	title     = {Distributed Compressive Sensing},
	journal   = {CoRR},
	volume    = {abs/0901.3403},
	year      = {2009},
	archivePrefix = {arXiv},
	eprint    = {0901.3403},
	timestamp = {Wed, 07 Jun 2017 14:40:04 +0200},
	biburl    = {https://dblp.org/rec/bib/journals/corr/abs-0901-3403},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{Greco2018,
	author={M. S. Greco and F. Gini and P. Stinco and K. Bell},
	journal={IEEE Signal Processing Magazine},
	title={Cognitive Radars: On the Road to Reality: Progress Thus Far and Possibilities for the Future},
	year={2018},
	volume={35},
	number={4},
	pages={112-125},
	doi={10.1109/MSP.2018.2822847},
	ISSN={1053-5888},
	month={July},
}

@ARTICLE{Stinco2016, 
	author={P. Stinco and M. S. Greco and F. Gini}, 
	journal={IET Radar, Sonar Navigation}, 
	title={Spectrum sensing and sharing for cognitive radars}, 
	year={2016}, 
	volume={10}, 
	number={3}, 
	pages={595-602}, 
	doi={10.1049/iet-rsn.2015.0372}, 
	ISSN={1751-8784}, 
	month={},
}
@InProceedings{Dias2010,
	author="Dias, Jos{\'e} G. and Vermunt, Jeroen K. and Ramos, Sofia",
	editor="Fink, Andreas and Lausen, Berthold and Seidel, Wilfried and Ultsch, Alfred",
	title="Mixture Hidden Markov Models in Finance Research",
	booktitle="Advances in Data Analysis, Data Handling and Business Intelligence",
	year="2010",
	publisher="Springer Berlin Heidelberg",
	address="Berlin, Heidelberg",
	pages="451--459",
}
@INPROCEEDINGS{Couvreur1996,
	author = {Christophe Couvreur},
	title = {Hidden Markov Models and Their Mixtures},
	booktitle = {DEA Report, Dep. of Mathematics, Universit\'e catholique de Louvain},
	year = {1996}
}
@inproceedings{Helske2016MixtureHM,
	title={Mixture Hidden Markov Models for Sequence Data : The seqHMM Package in R},
	author={Satu Helske and Jouni Helske},
	year={2016}
}

@incollection{NIPS2014_5518,
	title = {Spectral Learning of Mixture of Hidden Markov Models},
	author = {Subakan, Cem and Traa, Johannes and Smaragdis, Paris},
	booktitle = {Advances in Neural Information Processing Systems 27},
	editor = {Z. Ghahramani and M. Welling and C. Cortes and N. D. Lawrence and K. Q. Weinberger},
	pages = {2249--2257},
	year = {2014},
	publisher = {Curran Associates, Inc.},
	url = {http://papers.nips.cc/paper/5518-spectral-learning-of-mixture-of-hidden-markov-models.pdf}
}

@article{DeVicoFallani20130521,
	author = {De Vico Fallani, Fabrizio and Richiardi, Jonas and Chavez, Mario and Achard, Sophie},
	title = {Graph analysis of functional brain networks: practical issues in translational neuroscience},
	volume = {369},
	number = {1653},
	year = {2014},
	doi = {10.1098/rstb.2013.0521},
	publisher = {The Royal Society},
	issn = {0962-8436},
	journal = {Philosophical Transactions of the Royal Society of London B: Biological Sciences}
}

@ARTICLE{Bolton2018,
	author={T. A. W. Bolton and A. Tarun and V. Sterpenich and S. Schwartz and D. Van De Ville},
	journal={IEEE Transactions on Medical Imaging},
	title={Interactions Between Large-Scale Functional Brain Networks are Captured by Sparse Coupled HMMs},
	year={2018},
	volume={37},
	number={1},
	pages={230-240},
	ISSN={0278-0062},
	month={Jan},
}

@misc{Yang2018,
	Author = {Zhilin Yang and Jake Zhao and Bhuwan Dhingra and Kaiming He and William W. Cohen and Ruslan Salakhutdinov and Yann LeCun},
	Title = {GLoMo: Unsupervisedly Learned Relational Graphs as Transferable Representations},
	Year = {2018},
	journal = {arXiv preprint arXiv:1806.05662}
}

@article{Baum1972,
	title={An inequality and associated maximization technique in statistical estimation of probabilistic functions of a Markov process},
	author={Baum, Leonard},
	journal={Inequalities},
	volume={3},
	pages={1--8},
	year={1972}
}

@article{Dempster1977,
	title={Maximum likelihood from incomplete data via the EM algorithm},
	author={Dempster, Arthur P. and Laird, Nan M. and Rubin, Donald B.},
	journal={Journal of the royal statistical society. Series B (methodological)},
	pages={1--38},
	year={1977},
	publisher={JSTOR}
}

@article{Pavllo2018,
	title={QuaterNet: A Quaternion-based Recurrent Model for Human Motion},
	author={Pavllo, Dario and Grangier, David and Auli, Michael},
	journal={arXiv preprint arXiv:1805.06485},
	year={2018}
}

@inproceedings{Jain2016,
	title={Structural-RNN: Deep learning on spatio-temporal graphs},
	author={Jain, Ashesh and Zamir, Amir R and Savarese, Silvio and Saxena, Ashutosh},
	booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages={5308--5317},
	year={2016}
}

@inproceedings{Fragkiadaki2015,
	title={Recurrent network models for human dynamics},
	author={Fragkiadaki, Katerina and Levine, Sergey and Felsen, Panna and Malik, Jitendra},
	booktitle={Proceedings of the IEEE International Conference on Computer Vision},
	pages={4346--4354},
	year={2015}
}

@inproceedings{Martinez2017,
	title={On human motion prediction using recurrent neural networks},
	author={Martinez, Julieta and Black, Michael J and Romero, Javier},
	booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages={4674--4683},
	year={2017},
	organization={IEEE}
}

@article{Ionescu2014,
	author = {Ionescu, Catalin and Papava, Dragos and Olaru, Vlad and Sminchisescu, Cristian},
	title = {Human3.6M: Large Scale Datasets and Predictive Methods for 3D Human Sensing in Natural Environments},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	publisher = {IEEE Computer Society},
	year = {2014}
}

@inproceedings{Ionescu2011,
	author = {Catalin Ionescu and Fuxin Li and Cristian Sminchisescu},
	title = {Latent Structured Models for Human Pose Estimation},
	booktitle = {International Conference on Computer Vision},
	year = {2011}
}

@article{Rabiner1986,
	title={An introduction to hidden Markov models},
	author={Rabiner, Lawrence R and Juang, Biing-Hwang},
	journal={ieee assp magazine},
	volume={3},
	number={1},
	pages={4--16},
	year={1986},
	publisher={Citeseer}
}

@article{Kingma2014,
	title={Adam: A method for stochastic optimization},
	author={Kingma, Diederik P and Ba, Jimmy},
	journal={arXiv preprint arXiv:1412.6980},
	year={2014}
}

@InProceedings{Theagarajan2018,
	author = {Theagarajan, Rajkumar and Pala, Federico and Zhang, Xiu and Bhanu, Bir},
	title = {Soccer: Who Has the Ball? Generating Visual Analytics and Player Statistics},
	booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
	month = {June},
	year = {2018}
}

@INPROCEEDINGS{Tora2017, 
	author={M. R. Tora and J. Chen and J. J. Little}, 
	booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, 
	title={Classification of Puck Possession Events in Ice Hockey}, 
	year={2017}, 
	volume={}, 
	number={}, 
	pages={147-154}, 
	keywords={feature extraction;image classification;neural nets;sport;puck possession event classification;ice hockey;group activity recognition;recurrent neural network;feature extraction;pretrained convolutional neural network;context information;ice hockey dataset;Feature extraction;Ice;Logic gates;Computer vision;Activity recognition;Context modeling;Trajectory}, 
	doi={10.1109/CVPRW.2017.24}, 
	ISSN={2160-7516}, 
	month={July},}

@ELECTRONIC{hmmlearn,
	author={S. Lebedev},
	title={hmmlearn, hidden {M}arkov models in python, with scikit-learn like {API}.},
	note={\url{https://github.com/hmmlearn/hmmlearn}},}

@ELECTRONIC{omnetpp,
	title={{OMNeT}++, discrete event simulator.},
	note={\url{https://www.omnetpp.org}}}

@ELECTRONIC{inet,
	title={INET Framework.},
	note={\url{https://inet.omnetpp.org}},
}

@incollection{Bengio+chapter2007,
	author = {Bengio, Yoshua and LeCun, Yann},
	booktitle = {Large Scale Kernel Machines},
	publisher = {MIT Press},
	title = {Scaling Learning Algorithms Towards {AI}},
	year = {2007}
}

@article{Hinton06,
	author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
	journal = {Neural Computation},
	pages = {1527--1554},
	title = {A Fast Learning Algorithm for Deep Belief Nets},
	volume = {18},
	year = {2006}
}


@ARTICLE{Greco2018,
	author={M. S. Greco and F. Gini and P. Stinco and K. Bell},
	journal={IEEE Signal Processing Magazine},
	title={Cognitive Radars: On the Road to Reality: Progress Thus Far and Possibilities for the Future},
	year={2018},
	volume={35},
	number={4},
	pages={112-125},
	doi={10.1109/MSP.2018.2822847},
	ISSN={1053-5888},
	month={July},
}

@ARTICLE{Stinco2016, 
	author={P. Stinco and M. S. Greco and F. Gini}, 
	journal={IET Radar, Sonar Navigation}, 
	title={Spectrum sensing and sharing for cognitive radars}, 
	year={2016}, 
	volume={10}, 
	number={3}, 
	pages={595-602}, 
	doi={10.1049/iet-rsn.2015.0372}, 
	ISSN={1751-8784}, 
	month={},
}
@InProceedings{Dias2010,
	author="Dias, Jos{\'e} G. and Vermunt, Jeroen K. and Ramos, Sofia",
	editor="Fink, Andreas and Lausen, Berthold and Seidel, Wilfried and Ultsch, Alfred",
	title="Mixture Hidden Markov Models in Finance Research",
	booktitle="Advances in Data Analysis, Data Handling and Business Intelligence",
	year="2010",
	publisher="Springer Berlin Heidelberg",
	address="Berlin, Heidelberg",
	pages="451--459",
}
@INPROCEEDINGS{Couvreur1996,
	author = {Christophe Couvreur},
	title = {Hidden Markov Models and Their Mixtures},
	booktitle = {DEA Report, Dep. of Mathematics, Universit\'e catholique de Louvain},
	year = {1996}
}
@inproceedings{Helske2016MixtureHM,
	title={Mixture Hidden Markov Models for Sequence Data : The seqHMM Package in R},
	author={Satu Helske and Jouni Helske},
	year={2016}
}

@incollection{NIPS2014_5518,
	title = {Spectral Learning of Mixture of Hidden Markov Models},
	author = {Subakan, Cem and Traa, Johannes and Smaragdis, Paris},
	booktitle = {Advances in Neural Information Processing Systems 27},
	editor = {Z. Ghahramani and M. Welling and C. Cortes and N. D. Lawrence and K. Q. Weinberger},
	pages = {2249--2257},
	year = {2014},
	publisher = {Curran Associates, Inc.},
	url = {http://papers.nips.cc/paper/5518-spectral-learning-of-mixture-of-hidden-markov-models.pdf}
}


@ARTICLE{Bolton2018,
	author={T. A. W. Bolton and A. Tarun and V. Sterpenich and S. Schwartz and D. Van De Ville},
	journal={IEEE Transactions on Medical Imaging},
	title={Interactions Between Large-Scale Functional Brain Networks are Captured by Sparse Coupled HMMs},
	year={2018},
	volume={37},
	number={1},
	pages={230-240},
	ISSN={0278-0062},
	month={Jan},
}


@ARTICLE{Cheng2018, 
	author={N. {Cheng} and F. {Lyu} and J. {Chen} and W. {Xu} and H. {Zhou} and S. {Zhang} and X. S. {Shen}}, 
	journal={IEEE Network}, 
	title={Big Data Driven Vehicular Networks}, 
	year={2018}, 
	volume={32}, 
	number={6}, 
	pages={160-167}, 
	keywords={Big Data;learning (artificial intelligence);telecommunication network reliability;vehicular ad hoc networks;big data driven vehicular networks;information exchange;end devices;intelligent transportation systems;on-road mobile applications;VANET measurement data;vehicular connectivity;road safety-infotainment;machine learning schemes;Big Data;5G mobile communication;Wireless fidelity;Vehicular ad hod networks;Intelligent vehicles;Global Positioning System;Quality of service;Information exchange}, 
	doi={10.1109/MNET.2018.1700460}, 
	ISSN={0890-8044}, 
	month={November},}

@book{Gama2007,
	title={Learning from data streams: processing techniques in sensor networks},
	author={Gama, Jo{\~a}o and Gaber, Mohamed Medhat},
	year={2007},
	isbn={3540736786, 9783540736783},
	publisher={Springer}
}

@inproceedings{SpaMHMM,
	title={Spa{MHMM}: Sparse mixture of hidden {M}arkov models for graph connected entities},
	author={Pernes, Diogo and Cardoso, Jaime S},
	booktitle={2019 International Joint Conference on Neural Networks (IJCNN)},
	pages={1--10},
	year={2019},
	organization={IEEE}
}

@article{Bazzani2016,
	title={Recurrent mixture density network for spatiotemporal visual attention},
	author={Bazzani, Loris and Larochelle, Hugo and Torresani, Lorenzo},
	journal={arXiv preprint arXiv:1603.08199},
	year={2016}
}

@techreport{Bishop1994,
	title={Mixture density networks},
	author={Bishop, Christopher M},
	year={1994},
	institution={Citeseer}
}

@article{Graves2013,
	title={Generating sequences with recurrent neural networks},
	author={Graves, Alex},
	journal={arXiv preprint arXiv:1308.0850},
	year={2013}
}

@article{Blei2003,
	title={Latent dirichlet allocation},
	author={Blei, David M and Ng, Andrew Y and Jordan, Michael I},
	journal={Journal of Machine Learning Research},
	volume={3},
	number={Jan},
	pages={993--1022},
	year={2003}
}

@article{Kingma2013,
	title={Auto-encoding variational bayes},
	author={Kingma, Diederik P and Welling, Max},
	journal={arXiv preprint arXiv:1312.6114},
	year={2013}
}

@article{Khreich2012,
	title={A survey of techniques for incremental learning of {HMM} parameters},
	author={Khreich, Wael and Granger, Eric and Miri, Ali and Sabourin, Robert},
	journal={Information Sciences},
	volume={197},
	pages={105--130},
	year={2012},
	publisher={Elsevier}
}

@article{Baldi1994,
	title={Smooth on-line learning algorithms for hidden {M}arkov models},
	author={Baldi, Pierre and Chauvin, Yves},
	journal={Neural Computation},
	volume={6},
	number={2},
	pages={307--318},
	year={1994},
	publisher={MIT Press}
}

@article{Mongillo2008,
	author = {Mongillo, Gianluigi and Deneve, Sophie},
	year = {2008},
	month = {08},
	pages = {1706-16},
	title = {Online Learning with Hidden Markov Models},
	volume = {20},
	journal = {Neural computation},
	doi = {10.1162/neco.2008.10-06-351}
}

@article{Digalakis1999,
	title={Online adaptation of hidden {M}arkov models using incremental estimation algorithms},
	author={Digalakis, Vasilios V},
	journal={IEEE Transactions on Speech and Audio Processing},
	volume={7},
	number={3},
	pages={253--261},
	year={1999},
	publisher={IEEE}
}

@article{Ryden1997,
	title={On recursive estimation for hidden {M}arkov models},
	author={Ryd{\'e}n, Tobias},
	journal={Stochastic Processes and their Applications},
	volume={66},
	number={1},
	pages={79--96},
	year={1997},
	publisher={Elsevier}
}

@inproceedings{Laxman2008,
	author = {Laxman, Srivatsan and Tankasali, Vikram and W. White, Ryen},
	year = {2008},
	month = {08},
	pages = {453-461},
	title = {Stream prediction using a generative model based on frequent episodes in event sequences},
	booktitle = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	doi = {10.1145/1401890.1401947}
}

@article{Hofmann2011,
	title={Online intrusion alert aggregation with generative data stream modeling},
	author={Hofmann, Alexander and Sick, Bernhard},
	journal={IEEE Transactions on Dependable and Secure Computing},
	volume={8},
	number={2},
	pages={282--294},
	year={2011},
	publisher={IEEE}
}

@INPROCEEDINGS{Hayat2010, 
	author={M. Z. {Hayat} and M. R. {Hashemi}}, 
	booktitle={2010 International Conference of Soft Computing and Pattern Recognition}, 
	title={A DCT based approach for detecting novelty and concept drift in data streams}, 
	year={2010}, 
	volume={}, 
	number={}, 
	pages={373-378}, 
	keywords={computational complexity;discrete cosine transforms;learning (artificial intelligence);pattern clustering;DCT;discrete cosine transform;machine learning;concept drift;clustering algorithm;compact generative model;novelty detection;computational complexity;data stream;Discrete cosine transforms;Data models;Fitting;Memory management;Computational modeling;Clustering algorithms;Streaming media;Novelty detection;Concept drift;Clustering;Data stream;Classification}, 
	doi={10.1109/SOCPAR.2010.5686734}, 
	ISSN={}, 
	month={Dec},}

@article{SOHMMM,
	title={Hidden {M}arkov models on a self-organizing map for anomaly detection in 802.11 wireless networks},
	author={Allahdadi, Anisa and Pernes, Diogo and Cardoso, Jaime S and Morla, Ricardo},
	journal={Neural Computing and Applications},
	pages={1--18},
	year={2021},
	publisher={Springer}
}

@inproceedings{Anisa2013,
	title={Predicting short 802.11 sessions from {RADIUS} usage data},
	author={Allahdadi, Anisa and Morla, Ricardo and Aguiar, Ana and Cardoso, Jaime S},
	booktitle={Local Computer Networks Workshops (LCN Workshops), 2013 IEEE 38th Conference on},
	pages={1--8},
	year={2013},
	organization={IEEE}
}

@inproceedings{Anisa2014,
	title={Outlier detection in 802.11 wireless access points using Hidden {M}arkov Models},
	author={Allahdadi, Anisa and Morla, Ricardo and Cardoso, Jaime S},
	booktitle={Wireless and Mobile Networking Conference (WMNC), 2014 7th IFIP},
	pages={1--8},
	year={2014},
	organization={IEEE}
}

@Article{Anisa2019,
	author="Allahdadi, Anisa
	and Morla, Ricardo",
	title="Anomaly Detection and Modeling in 802.11 Wireless Networks",
	journal="Journal of Network and Systems Management",
	year="2019",
	month="Jan",
	day="01",
	volume="27",
	number="1",
	pages="3--38",
	issn="1573-7705"
}

@article{Anisa2017,
	author = {Anisa Allahdadi and Ricardo Morla and Jaime S Cardoso},
	title ={802.11 wireless simulation and anomaly detection using {HMM} and {UBM}},
	journal = {SIMULATION},
	volume = {96},
	number = {12},
	pages = {939-956},
	year = {2020},
	doi = {10.1177/0037549720958480},
	},
	eprint = { 
	https://doi.org/10.1177/0037549720958480
	}
	,
	note = {
		\url{https://doi.org/10.1177/0037549720958480	
	},
	abstract = { Despite the growing popularity of 802.11 wireless networks, users often suffer from connectivity problems and performance issues due to unstable radio conditions and dynamic user behavior, among other reasons. Anomaly detection and distinction are in the thick of major challenges that network managers encounter. The difficulty of monitoring broad and complex Wireless Local Area Networks, that often requires heavy instrumentation of the user devices, makes anomaly detection analysis even harder. In this paper we exploit 802.11 access point usage data and propose an anomaly detection technique based on Hidden Markov Model (HMM) and Universal Background Model (UBM) on data that is inexpensive to obtain. We then generate a number of network anomalous scenarios in OMNeT++/INET network simulator and compare the detection outcomes with those in baseline approaches—RawData and Principal Component Analysis. The experimental results show the superiority of HMM and HMM-UBM models in detection precision and sensitivity. }
}

@inproceedings{Somervuo2000,
	title={Competing hidden {M}arkov models on the self-organizing map},
	author={Somervuo, Panu},
	booktitle={Neural Networks, 2000. IJCNN 2000, Proceedings of the IEEE-INNS-ENNS International Joint Conference on},
	volume={3},
	pages={169--174},
	year={2000},
	organization={IEEE}
}

@inproceedings{Kurimo1996,
	title={Using the Self-Organizing Map to speed up the probability density estimation for speech recognition with mixture density {HMM}s},
	author={Kurimo, Mikko and Somervuo, Panu},
	booktitle={Spoken Language, 1996. ICSLP 96. Proceedings, Fourth International Conference on},
	volume={1},
	pages={358--361},
	year={1996},
	organization={IEEE}
}


@article{Ferles2013b,
	title={Scaled self-organizing map--hidden {M}arkov model architecture for biological sequence clustering},
	author={Ferles, Christos and Siolas, Georgios and Stafylopatis, Andreas},
	journal={Applied Artificial Intelligence},
	volume={27},
	number={6},
	pages={461--495},
	year={2013},
	publisher={Taylor \& Francis}
}


@book{Kohonen1995,
	title={Self-Organizing Maps},
	author={Kohonen, Teuvo},
	year={1995},
	publisher={Springer}
}

@inproceedings{Gen2012,
	title={The spherical hidden {M}arkov self organizing map for learning time series data},
	author={Niina, Gen and Dozono, Hiroshi},
	booktitle={International Conference on Artificial Neural Networks},
	pages={563--570},
	year={2012},
	organization={Springer}
}

@inproceedings{Yamaguchi2010,
	title={Self-organizing hidden {M}arkov models},
	author={Yamaguchi, Nobuhiko},
	booktitle={International Conference on Neural Information Processing},
	pages={454--461},
	year={2010},
	organization={Springer}
}

@inproceedings{Ref17,
	title={Recognizing human actions using silhouette-based {HMM}},
	author={Martinez-Contreras, Francisco and Orrite-Urunuela, Carlos and Herrero-Jaraba, Elias and Ragheb, Hossein and Velastin, Sergio A},
	booktitle={Advanced Video and Signal Based Surveillance, 2009. AVSS'09. Sixth IEEE International Conference on},
	pages={43--48},
	year={2009},
	organization={IEEE}
}


@article{Rabiner1989,
	title={A tutorial on hidden {M}arkov models and selected applications in speech recognition},
	author={Rabiner, Lawrence R},
	journal={Proceedings of the IEEE},
	volume={77},
	number={2},
	pages={257--286},
	year={1989},
	publisher={IEEE}
}

@article{Caridakis2010,
	title={{SOMM}: Self organizing {M}arkov map for gesture recognition},
	author={Caridakis, George and Karpouzis, Kostas and Drosopoulos, Athanasios and Kollias, Stefanos},
	journal={Pattern Recognition Letters},
	volume={31},
	number={1},
	pages={52--59},
	year={2010},
	publisher={Elsevier}
}

@article{Cho2002,
	title={Incorporating soft computing techniques into a probabilistic intrusion detection system},
	author={Cho, Sung-Bae},
	journal={IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
	volume={32},
	number={2},
	pages={154--160},
	year={2002},
	publisher={IEEE}
}

@article{Wang2006,
	title={Profiling program behavior for anomaly intrusion detection based on the transition and frequency property of computer audit data},
	author={Wang, Wei and Guan, Xiaohong and Zhang, Xiangliang and Yang, Liwei},
	journal={{C}omputers \& {S}ecurity},
	volume={25},
	number={7},
	pages={539--550},
	year={2006},
	publisher={Elsevier}
}

@inproceedings{Jaziri2011,
	title={{SOS-HMM}: self-organizing structure of hidden {M}arkov model},
	author={Jaziri, Rakia and Lebbah, Mustapha and Bennani, Youn{\`e}s and Chenot, Jean-Hugues},
	booktitle={International Conference on Artificial Neural Networks},
	pages={87--94},
	year={2011},
	organization={Springer}
}

@article{Juang1985,
	title={A probabilistic distance measure for hidden {M}arkov models},
	author={Juang, B-H and Rabiner, Lawrence R},
	journal={AT\&T {T}echnical {J}ournal},
	volume={64},
	number={2},
	pages={391--408},
	year={1985},
	publisher={Wiley Online Library}
}

@incollection{Ferles2017,
	title={Self-Organizing Hidden {M}arkov Model Map ({SOHMMM}): {B}iological sequence clustering and cluster visualization},
	author={Ferles, Christos and Beaufort, William-Scott and Ferle, Vanessa},
	booktitle={Hidden {M}arkov Models},
	pages={83--101},
	year={2017},
	publisher={Springer}
}

@article{Ferles2013,
	title = "Self-Organizing Hidden {M}arkov Model Map ({SOHMMM})",
	journal = "Neural Networks",
	volume = "48",
	pages = "133 - 147",
	year = "2013",
	issn = "0893-6080",
	doi = "https://doi.org/10.1016/j.neunet.2013.07.011",
	author = "Christos Ferles and Andreas Stafylopatis",
	keywords = "Self-Organizing Map (SOM), Hidden Markov Model (HMM), Unsupervised learning, Clustering, Spatiotemporal, DNA/RNA/protein sequences",
	abstract = "A hybrid approach combining the Self-Organizing Map (SOM) and the Hidden Markov Model (HMM) is presented. The Self-Organizing Hidden Markov Model Map (SOHMMM) establishes a cross-section between the theoretic foundations and algorithmic realizations of its constituents. The respective architectures and learning methodologies are fused in an attempt to meet the increasing requirements imposed by the properties of deoxyribonucleic acid (DNA), ribonucleic acid (RNA), and protein chain molecules. The fusion and synergy of the SOM unsupervised training and the HMM dynamic programming algorithms bring forth a novel on-line gradient descent unsupervised learning algorithm, which is fully integrated into the SOHMMM. Since the SOHMMM carries out probabilistic sequence analysis with little or no prior knowledge, it can have a variety of applications in clustering, dimensionality reduction and visualization of large-scale sequence spaces, and also, in sequence discrimination, search and classification. Two series of experiments based on artificial sequence data and splice junction gene sequences demonstrate the SOHMMM’s characteristics and capabilities."
}

@inproceedings{Ferles2008,
	title={Sequence clustering with the self-organizing hidden {M}arkov model map},
	author={Ferles, Christos and Stafylopatis, Andreas},
	booktitle={2008 8th IEEE International Conference on BioInformatics and BioEngineering},
	pages={1--7},
	year={2008},
	organization={IEEE}
}

@article{Lebbah2015,
	title={Probabilistic self-organizing map for clustering and visualizing non-{IID} data},
	author={Lebbah, Mustapha and Jaziri, Rakia and Bennani, Youn{\`e}s and Chenot, Jean-Hugues},
	journal={International Journal of Computational Intelligence and Applications},
	volume={14},
	number={02},
	pages={1550007},
	year={2015},
	publisher={World Scientific}
}


@article{Morimoto2016,
	title={Hidden {M}arkov models and self-organizing maps applied to stroke incidence},
	author={Morimoto, Hiroshi},
	journal={Open Journal of Applied Sciences},
	volume={6},
	number={3},
	pages={158--168},
	year={2016},
	publisher={Scientific Research Publishing}
}


@article{MODAFM,
	title={Tackling unsupervised multi-source domain adaptation with optimism and consistency}, 
	author={Diogo Pernes and Jaime S. Cardoso},
	year={2020},
	eprint={2009.13939},
	archivePrefix={arXiv},
	journal={CoRR},
	volume={abs/2009.13939},
	primaryClass={cs.LG}
}


@mastersthesis{ThesisFrancisco,
	title={Adversarial Domain Adaptation for Sensor Networks},
	author={Francisco Tuna de Andrade},
	year={2020},
	school={Faculdade de Engenharia da Universidade do Porto},
}

@inproceedings{BenDavid2007,
	title={Analysis of representations for domain adaptation},
	author={Ben-David, Shai and Blitzer, John and Crammer, Koby and Pereira, Fernando},
	booktitle={Advances in Neural Information Processing Systems},
	pages={137--144},
	year={2007}
}

@article{BenDavid2010,
	title={A theory of learning from different domains},
	author={Ben-David, Shai and Blitzer, John and Crammer, Koby and Kulesza, Alex and Pereira, Fernando and Vaughan, Jennifer Wortman},
	journal={Machine learning},
	volume={79},
	number={1-2},
	pages={151--175},
	year={2010},
	publisher={Springer}
}

@inproceedings{Ganin2015,
	title={Unsupervised Domain Adaptation by Backpropagation},
	author={Ganin, Yaroslav and Lempitsky, Victor},
	booktitle={International Conference on Machine Learning},
	pages={1180--1189},
	year={2015}
}

@inproceedings{Zhao2018,
	title={Adversarial multiple source domain adaptation},
	author={Zhao, Han and Zhang, Shanghang and Wu, Guanhang and Moura, Jos{\'e} MF and Costeira, Joao P and Gordon, Geoffrey J},
	booktitle={Advances in Neural Information Processing Systems},
	pages={8559--8570},
	year={2018}
}

@inproceedings{Guo2018,
	title={Multi-Source Domain Adaptation with Mixture of Experts},
	author={Guo, Jiang and Shah, Darsh and Barzilay, Regina},
	booktitle={Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
	pages={4694--4703},
	year={2018}
}

@inproceedings{Zhao2019,
	title={On Learning Invariant Representations for Domain Adaptation},
	author={Zhao, Han and Des Combes, Remi Tachet and Zhang, Kun and Gordon, Geoffrey},
	booktitle={International Conference on Machine Learning},
	pages={7523--7532},
	year={2019}
}

@article{Sohn2020,
	title={Fixmatch: Simplifying semi-supervised learning with consistency and confidence},
	author={Sohn, Kihyuk and Berthelot, David and Li, Chun-Liang and Zhang, Zizhao and Carlini, Nicholas and Cubuk, Ekin D and Kurakin, Alex and Zhang, Han and Raffel, Colin},
	journal={arXiv preprint arXiv:2001.07685},
	year={2020}
}

@article{Cubuk2019,
	title={RandAugment: Practical data augmentation with no separate search},
	author={Cubuk, Ekin D and Zoph, Barret and Shlens, Jonathon and Le, Quoc V},
	journal={arXiv preprint arXiv:1909.13719},
	year={2019}
}

@article{Srivastava2014,
	title={Dropout: a simple way to prevent neural networks from overfitting},
	author={Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
	journal={The journal of machine learning research},
	volume={15},
	number={1},
	pages={1929--1958},
	year={2014},
	publisher={JMLR. org}
}

@article{LeCun1998,
	title={Gradient-based learning applied to document recognition},
	author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
	journal={Proceedings of the IEEE},
	volume={86},
	number={11},
	pages={2278--2324},
	year={1998},
	publisher={Ieee}
}

@inproceedings{Netzer2011,
	title={Reading digits in natural images with unsupervised feature learning},
	author={Netzer, Yuval and Wang, Tao and Coates, Adam and Bissacco, Alessandro and Wu, Bo and Ng, Andrew Y},
	booktitle={Advances in Neural Information Processing Systems},
	year={2011}
}~

@inproceedings{Saenko2010,
	title={Adapting visual category models to new domains},
	author={Saenko, Kate and Kulis, Brian and Fritz, Mario and Darrell, Trevor},
	booktitle={European Conference on Computer Vision},
	pages={213--226},
	year={2010},
	organization={Springer}
}

@inproceedings{Pei2018,
	title={Multi-adversarial domain adaptation},
	author={Pei, Zhongyi and Cao, Zhangjie and Long, Mingsheng and Wang, Jianmin},
	booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
	year={2018}
}

@inproceedings{Blitzer2007,
	title={Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification},
	author={Blitzer, John and Dredze, Mark and Pereira, Fernando},
	booktitle={Proceedings of the 45th annual meeting of the association of computational linguistics},
	pages={440--447},
	year={2007}
}

@article{Chen2012,
	title={Marginalized denoising autoencoders for domain adaptation},
	author={Chen, Minmin and Xu, Zhixiang and Weinberger, Kilian and Sha, Fei},
	journal={arXiv preprint arXiv:1206.4683},
	year={2012}
}

@inproceedings{Torralba2011,
	title={Unbiased look at dataset bias},
	author={Torralba, Antonio and Efros, Alexei A},
	booktitle={CVPR 2011},
	pages={1521--1528},
	year={2011},
	organization={IEEE}
}

@inproceedings{Hoffman2018,
	title={Algorithms and theory for multiple-source adaptation},
	author={Hoffman, Judy and Mohri, Mehryar and Zhang, Ningshan},
	booktitle={Advances in Neural Information Processing Systems},
	pages={8246--8256},
	year={2018}
}

@inproceedings{Blitzer2008,
	title={Learning bounds for domain adaptation},
	author={Blitzer, John and Crammer, Koby and Kulesza, Alex and Pereira, Fernando and Wortman, Jennifer},
	booktitle={Advances in Neural Information Processing Systems},
	pages={129--136},
	year={2008}
}

@article{Gopalan2013,
	title={Unsupervised adaptation across domain shifts by generating intermediate data representations},
	author={Gopalan, Raghuraman and Li, Ruonan and Chellappa, Rama},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
	volume={36},
	number={11},
	pages={2288--2302},
	year={2013},
	publisher={IEEE}
}

@article{Cortes2014,
	title={Domain adaptation and sample bias correction theory and algorithm for regression},
	author={Cortes, Corinna and Mohri, Mehryar},
	journal={Theoretical Computer Science},
	volume={519},
	pages={103--126},
	year={2014},
	publisher={Elsevier}
}

@inproceedings{Mansour2009,
	title={Domain adaptation: Learning bounds and algorithms},
	author={Mansour, Yishay and Mohri, Mehryar and Rostamizadeh, Afshin},
	booktitle={22nd Conference on Learning Theory, COLT 2009},
	year={2009}
}

@article{Ajakan2014,
	title={Domain-adversarial neural networks},
	author={Ajakan, Hana and Germain, Pascal and Larochelle, Hugo and Laviolette, Fran{\c{c}}ois and Marchand, Mario},
	journal={arXiv preprint arXiv:1412.4446},
	year={2014}
}

@inproceedings{Becker2013,
	title={Non-linear domain adaptation with boosting},
	author={Becker, Carlos J and Christoudias, Christos M and Fua, Pascal},
	booktitle={Advances in Neural Information Processing Systems},
	pages={485--493},
	year={2013}
}

@inproceedings{Tzeng2017,
	title={Adversarial discriminative domain adaptation},
	author={Tzeng, Eric and Hoffman, Judy and Saenko, Kate and Darrell, Trevor},
	booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages={7167--7176},
	year={2017}
}

@inproceedings{Fernando2013,
	title={Unsupervised visual domain adaptation using subspace alignment},
	author={Fernando, Basura and Habrard, Amaury and Sebban, Marc and Tuytelaars, Tinne},
	booktitle={Proceedings of the IEEE International Conference on Computer Vision},
	pages={2960--2967},
	year={2013}
}

@inproceedings{Sun2016,
	title={Return of frustratingly easy domain adaptation},
	author={Sun, Baochen and Feng, Jiashi and Saenko, Kate},
	booktitle={Thirtieth AAAI Conference on Artificial Intelligence},
	year={2016}
}

@inproceedings{Louizos2015,
	title={The variational fair autoencoder},
	author={Louizos, Christos and Swersky, Kevin and Li, Yujia and Welling, Max and Zemel, Richard},
	booktitle={International Conference on Learning Representations},
	year={2016}
}


@article{Long2015,
	title={Learning transferable features with deep adaptation networks},
	author={Long, Mingsheng and Cao, Yue and Wang, Jianmin and Jordan, Michael I},
	journal={arXiv preprint arXiv:1502.02791},
	year={2015}
}

@inproceedings{Jhuo2012,
	title={Robust visual domain adaptation with low-rank reconstruction},
	author={Jhuo, I-Hong and Liu, Dong and Lee, DT and Chang, Shih-Fu},
	booktitle={2012 IEEE Conference on Computer Vision and Pattern Recognition},
	pages={2168--2175},
	year={2012},
	organization={IEEE}
}

@inproceedings{Zhang2013,
	title={Domain adaptation under target and conditional shift},
	author={Zhang, Kun and Sch{\"o}lkopf, Bernhard and Muandet, Krikamol and Wang, Zhikun},
	booktitle={International Conference on Machine Learning},
	pages={819--827},
	year={2013}
}

@inproceedings{Zhang2015,
	title={Multi-source domain adaptation: A causal view},
	author={Zhang, Kun and Gong, Mingming and Sch{\"o}lkopf, Bernhard},
	booktitle={Twenty-ninth AAAI conference on artificial intelligence},
	year={2015}
}

@article{Zhang2020,
	title={Domain Adaptation As a Problem of Inference on Graphical Models},
	author={Zhang, Kun and Gong, Mingming and Stojanov, Petar and Huang, Biwei and Glymour, Clark},
	journal={arXiv preprint arXiv:2002.03278},
	year={2020}
}

@article{Storkey2009,
	title={When training and test sets are different: characterizing learning transfer},
	author={Storkey, Amos},
	journal={Dataset shift in machine learning},
	pages={3--28},
	year={2009},
	publisher={Citeseer}
}

@inproceedings{Iyer2004,
	title={Maximum mean discrepancy for class ratio estimation: Convergence bounds and kernel selection},
	author={Iyer, Arun and Nath, Saketha and Sarawagi, Sunita},
	booktitle={International Conference on Machine Learning},
	pages={530--538},
	year={2014}
}

@inproceedings{Gong2016,
	title={Domain adaptation with conditional transferable components},
	author={Gong, Mingming and Zhang, Kun and Liu, Tongliang and Tao, Dacheng and Glymour, Clark and Sch{\"o}lkopf, Bernhard},
	booktitle={International Conference on Machine Learning},
	pages={2839--2848},
	year={2016}
}

@inproceedings{Long2013,
	title={Transfer feature learning with joint distribution adaptation},
	author={Long, Mingsheng and Wang, Jianmin and Ding, Guiguang and Sun, Jiaguang and Yu, Philip S},
	booktitle={Proceedings of the IEEE International Conference on Computer Vision},
	pages={2200--2207},
	year={2013}
}

@inproceedings{Daume2010,
	title={Frustratingly easy semi-supervised domain adaptation},
	author={Daum{\'e} III, Hal and Kumar, Abhishek and Saha, Avishek},
	booktitle={Proceedings of the 2010 Workshop on Domain Adaptation for Natural Language Processing},
	pages={53--59},
	year={2010},
	organization={Association for Computational Linguistics}
}

@inproceedings{Kumar2010,
	title={Co-regularization based semi-supervised domain adaptation},
	author={Kumar, Abhishek and Saha, Avishek and Daume, Hal},
	booktitle={Advances in Neural Information Processing Systems},
	pages={478--486},
	year={2010}
}

@inproceedings{Yao2015,
	title={Semi-supervised domain adaptation with subspace learning for visual recognition},
	author={Yao, Ting and Pan, Yingwei and Ngo, Chong-Wah and Li, Houqiang and Mei, Tao},
	booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages={2142--2150},
	year={2015}
}

@inproceedings{Donahue2013,
	title={Semi-supervised domain adaptation with instance constraints},
	author={Donahue, Jeff and Hoffman, Judy and Rodner, Erik and Saenko, Kate and Darrell, Trevor},
	booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages={668--675},
	year={2013}
}

@inproceedings{Saito2019,
	title={Semi-supervised domain adaptation via minimax entropy},
	author={Saito, Kuniaki and Kim, Donghyun and Sclaroff, Stan and Darrell, Trevor and Saenko, Kate},
	booktitle={Proceedings of the IEEE International Conference on Computer Vision},
	pages={8050--8058},
	year={2019}
}

@inproceedings{Long2016,
	title={Unsupervised domain adaptation with residual transfer networks},
	author={Long, Mingsheng and Zhu, Han and Wang, Jianmin and Jordan, Michael I},
	booktitle={Advances in Neural Information Processing Systems},
	pages={136--144},
	year={2016}
}

@inproceedings{Baktashmotlagh2013,
	title={Unsupervised domain adaptation by domain invariant projection},
	author={Baktashmotlagh, Mahsa and Harandi, Mehrtash T and Lovell, Brian C and Salzmann, Mathieu},
	booktitle={Proceedings of the IEEE International Conference on Computer Vision},
	pages={769--776},
	year={2013}
}

@inproceedings{Kang2019,
	title={Contrastive adaptation network for unsupervised domain adaptation},
	author={Kang, Guoliang and Jiang, Lu and Yang, Yi and Hauptmann, Alexander G},
	booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages={4893--4902},
	year={2019}
}

@inproceedings{Kim2017,
	title={Domain attention with an ensemble of experts},
	author={Kim, Young-Bum and Stratos, Karl and Kim, Dongchan},
	booktitle={Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
	pages={643--653},
	year={2017}
}


@article{Sugiyama2008,
	title={Direct importance estimation for covariate shift adaptation},
	author={Sugiyama, Masashi and Suzuki, Taiji and Nakajima, Shinichi and Kashima, Hisashi and von B{\"u}nau, Paul and Kawanabe, Motoaki},
	journal={Annals of the Institute of Statistical Mathematics},
	volume={60},
	number={4},
	pages={699--746},
	year={2008},
	publisher={Springer}
}

@inproceedings{Cortes2010,
	title={Learning bounds for importance weighting},
	author={Cortes, Corinna and Mansour, Yishay and Mohri, Mehryar},
	booktitle={Advances in Neural Information Processing Systems},
	pages={442--450},
	year={2010}
}

@article{DeSIRe,
	title={DeSIRe: Deep Signer-Invariant Representations for Sign Language Recognition},
	author={Ferreira, Pedro M and Pernes, Diogo and Rebelo, Ana and Cardoso, Jaime S},
	journal={IEEE Transactions on Systems, Man, and Cybernetics: Systems},
	year={2019},
	publisher={IEEE}
}


@inproceedings{AdvSInvConf,
	title={Learning signer-invariant representations with adversarial training},
	author={Ferreira, Pedro M and Pernes, Diogo and Rebelo, Ana and Cardoso, Jaime S},
	booktitle={Twelfth International Conference on Machine Vision (ICMV 2019)},
	volume={11433},
	pages={114333D},
	year={2020},
	organization={International Society for Optics and Photonics}
}

@article{AdvSInvJournal,
	title={Signer-Independent Sign Language Recognition with Adversarial Neural Networks},
	author={Ferreira, Pedro M and Pernes, Diogo and Rebelo, Ana and Cardoso, Jaime S},
	journal={International Journal of Machine Learning and Computing},
	volume={11},
	number={2},
	year={2021}
}

@INPROCEEDINGS{AdvInvAttack,
	author={P. M. {Ferreira} and A. F. {Sequeira} and D. {Pernes} and A. {Rebelo} and J. S. {Cardoso}},
	booktitle={2019 International Conference of the Biometrics Special Interest Group (BIOSIG)}, 
	title={Adversarial learning for a robust iris presentation attack detection method against unseen attack presentations}, 
	year={2019},
	volume={},
	number={},
	pages={1-7},
	doi={}}

@inproceedings{Sebag2019,
	title={Multi-Domain Adversarial Learning},
	author={Alice Schoenauer-Sebag and Louise Heinrich and Marc Schoenauer and Michele Sebag and Lani Wu and Steve Altschuler},
	booktitle={International Conference on Learning Representations},
	year={2019},
}

@inproceedings{He2016,
	title={Deep residual learning for image recognition},
	author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages={770--778},
	year={2016}
}

@article{Casselman2019,
	author = {Casselman, Ben and Satariano, Adam},
	year = {2019},
	title = {Amazon’s Latest Experiment: Retraining Its Work Force},
	journal = {New York Times},
	url = {https://www.nytimes.com/2019/07/11/technology/amazon-workers-retraining-automation.html?smtyp=cur&smid=tw-nytimesbusiness},
	urldate = {2020-05-14}
}

@article{Murgia2019,
	title = {AI’s new workforce: the data-labelling industry spreads globally},
	author = {Madhumita Murgia},
	year = {2019},
	journal = {Financial Times},
	url = {https://www.ft.com/content/56dde36c-aa40-11e9-984c-fac8325aaa04},
	urldate = {2020-05-14}
}

@article{Frey2017,
	title={The future of employment: How susceptible are jobs to computerisation?},
	author={Frey, Carl Benedikt and Osborne, Michael A},
	journal={Technological forecasting and social change},
	volume={114},
	pages={254--280},
	year={2017},
	publisher={Elsevier}
}

@article{WEC2018,
	title={The Future of Jobs Report},
	journal={World Economic Forum},
	year={2018},
}

@article{McKinsey,
	title={The future of work in America: People and places, today and tomorrow},
	year={2019},
	journal={McKinsey Global Institute},
	url= {https://www.mckinsey.com/featured-insights/future-of-work/the-future-of-work-in-america-people-and-places-today-and-tomorrow},
	urldate = {2020-05-14}
}

@article{TheBatch2020,
	title={ImageNet Gets a Makeover},
	journal={The Batch},
	publisher={deeplearning.ai},
	year={2020},
	url={https://blog.deeplearning.ai/blog/the-batch-facebook-takes-on-deepfakes-google-ai-battles-cancer-researchers-fight-imagenet-bias-ai-grows-globally},
	urldate={2020-05-14}
}

@inproceedings{Peng2019,
	title={Moment matching for multi-source domain adaptation},
	author={Peng, Xingchao and Bai, Qinxun and Xia, Xide and Huang, Zijun and Saenko, Kate and Wang, Bo},
	booktitle={Proceedings of the IEEE International Conference on Computer Vision},
	pages={1406--1415},
	year={2019}
}

@inproceedings{Cortes2011,
	author="Cortes, Corinna
	and Mohri, Mehryar",
	editor="Kivinen, Jyrki
	and Szepesv{\'a}ri, Csaba
	and Ukkonen, Esko
	and Zeugmann, Thomas",
	title="Domain Adaptation in Regression",
	booktitle="Algorithmic Learning Theory",
	year="2011",
	publisher="Springer Berlin Heidelberg",
	address="Berlin, Heidelberg",
	pages="308--323",
	abstract="This paper presents a series of new results for domain adaptation in the regression setting. We prove that the discrepancy is a distance for the squared loss when the hypothesis set is the reproducing kernel Hilbert space induced by a universal kernel such as the Gaussian kernel. We give new pointwise loss guarantees based on the discrepancy of the empirical source and target distributions for the general class of kernel-based regularization algorithms. These bounds have a simpler form than previous results and hold for a broader class of convex loss functions not necessarily differentiable, including Lqlosses and the hinge loss. We extend the discrepancy minimization adaptation algorithm to the more significant case where kernels are used and show that the problem can be cast as an SDP similar to the one in the feature space. We also show that techniques from smooth optimization can be used to derive an efficient algorithm for solving such SDPs even for very high-dimensional feature spaces. We have implemented this algorithm and report the results of experiments demonstrating its benefits for adaptation and show that, unlike previous algorithms, it can scale to large data sets of tens of thousands or more points.",
	isbn="978-3-642-24412-4"
}

@inproceedings{Lipton2018,
	title = 	 {Detecting and Correcting for Label Shift with Black Box Predictors},
	author =       {Lipton, Zachary and Wang, Yu-Xiang and Smola, Alexander},
	booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
	pages = 	 {3122--3130},
	year = 	 {2018},
	editor = 	 {Jennifer Dy and Andreas Krause},
	volume = 	 {80},
	series = 	 {Proceedings of Machine Learning Research},
	address = 	 {Stockholmsmässan, Stockholm Sweden},
	month = 	 {10--15 Jul},
	publisher =    {PMLR},
	abstract = 	 {Faced with distribution shift between training and test set, we wish to detect and quantify the shift, and to correct our classifiers without test set labels. Motivated by medical diagnosis, where diseases (targets), cause symptoms (observations), we focus on label shift, where the label marginal p(y) changes but the conditional p(x| y) does not. We propose Black Box Shift Estimation (BBSE) to estimate the test distribution p(y). BBSE exploits arbitrary black box predictors to reduce dimensionality prior to shift correction. While better predictors give tighter estimates, BBSE works even when predictors are biased, inaccurate, or uncalibrated, so long as their confusion matrices are invertible. We prove BBSE’s consistency, bound its error, and introduce a statistical test that uses BBSE to detect shift. We also leverage BBSE to correct classifiers. Experiments demonstrate accurate estimates and improved prediction, even on high-dimensional datasets of natural images.}
}

@inproceedings{Chan2005,
	author = {Chan, Yee Seng and Ng, Hwee Tou},
	title = {Word Sense Disambiguation with Distribution Estimation},
	year = {2005},
	publisher = {Morgan Kaufmann Publishers Inc.},
	address = {San Francisco, CA, USA},
	abstract = {A word sense disambiguation (WSD) system trained on one domain and applied to a different domain will show a decrease in performance. One major reason is the different sense distributions between different domains. This paper presents novel application of two distribution estimation algorithms to provide estimates of the sense distribution of the new domain data set. Even though our training examples are automatically gathered from parallel corpora, the sense distributions estimated are good enough to achieve a relative improvement of 56% when incorporated into our WSD system.},
	booktitle = {Proceedings of the 19th International Joint Conference on Artificial Intelligence},
	pages = {1010–1015},
	numpages = {6},
	location = {Edinburgh, Scotland},
	series = {IJCAI'05}
}

@article{Sugiyama2007,
	author = {Sugiyama, Masashi and Krauledat, Matthias and Müller, Klaus-Robert},
	year = {2007},
	month = {05},
	pages = {985-1005},
	title = {Covariate Shift Adaptation by Importance Weighted Cross Validation.},
	volume = {8},
	journal = {Journal of Machine Learning Research}
}

@article{Shimodaira2000,
	title = {Improving predictive inference under covariate shift by weighting the log-likelihood function},
	journal = {Journal of Statistical Planning and Inference},
	volume = {90},
	number = {2},
	pages = {227-244},
	year = {2000},
	issn = {0378-3758},
	doi = {https://doi.org/10.1016/S0378-3758(00)00115-4},

	author = {Hidetoshi Shimodaira},
	keywords = {Akaike information criterion, Design of experiments, Importance sampling, Kullback–Leibler divergence, Misspecification, Sample surveys, Weighted least squares},
	abstract = {A class of predictive densities is derived by weighting the observed samples in maximizing the log-likelihood function. This approach is effective in cases such as sample surveys or design of experiments, where the observed covariate follows a different distribution than that in the whole population. Under misspecification of the parametric model, the optimal choice of the weight function is asymptotically shown to be the ratio of the density function of the covariate in the population to that in the observations. This is the pseudo-maximum likelihood estimation of sample surveys. The optimality is defined by the expected Kullback–Leibler loss, and the optimal weight is obtained by considering the importance sampling identity. Under correct specification of the model, however, the ordinary maximum likelihood estimate (i.e. the uniform weight) is shown to be optimal asymptotically. For moderate sample size, the situation is in between the two extreme cases, and the weight function is selected by minimizing a variant of the information criterion derived as an estimate of the expected loss. The method is also applied to a weighted version of the Bayesian predictive density. Numerical examples as well as Monte-Carlo simulations are shown for polynomial regression. A connection with the robust parametric estimation is discussed.}
}

@article{Webb2018,
	title={Analyzing concept drift and shift from sample data},
	author={Webb, Geoffrey I and Lee, Loong Kuan and Goethals, Bart and Petitjean, Fran{\c{c}}ois},
	journal={Data Mining and Knowledge Discovery},
	volume={32},
	number={5},
	pages={1179--1199},
	year={2018},
	publisher={Springer}
}

@ARTICLE{Courty2015,
	author={N. {Courty} and R. {Flamary} and D. {Tuia} and A. {Rakotomamonjy}},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
	title={Optimal Transport for Domain Adaptation}, 
	year={2017},
	volume={39},
	number={9},
	pages={1853-1865},
	doi={10.1109/TPAMI.2016.2615921}
}

@article{Gama2014,
	author = {Gama, Joao and \v{Z}liobaitundefined, Indrundefined and Bifet, Albert and Pechenizkiy, Mykola and Bouchachia, Abdelhamid},
	title = {A Survey on Concept Drift Adaptation},
	year = {2014},
	issue_date = {April 2014},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	volume = {46},
	number = {4},
	issn = {0360-0300},
	doi = {10.1145/2523813},
	abstract = {Concept drift primarily refers to an online supervised learning scenario when the relation between the input data and the target variable changes over time. Assuming a general knowledge of supervised learning in this article, we characterize adaptive learning processes; categorize existing strategies for handling concept drift; overview the most representative, distinct, and popular techniques and algorithms; discuss evaluation methodology of adaptive algorithms; and present a set of illustrative applications. The survey covers the different facets of concept drift in an integrated way to reflect on the existing scattered state of the art. Thus, it aims at providing a comprehensive introduction to the concept drift adaptation for researchers, industry analysts, and practitioners.},
	journal = {ACM Comput. Surv.},
	month = mar,
	articleno = {44},
	numpages = {37},
	keywords = {adaptive learning, Concept drift, data streams, change detection}
}

@article{Rojas2018,
	title={Invariant models for causal transfer learning},
	author={Rojas-Carulla, Mateo and Sch{\"o}lkopf, Bernhard and Turner, Richard and Peters, Jonas},
	journal={The Journal of Machine Learning Research},
	volume={19},
	number={1},
	pages={1309--1342},
	year={2018},
	publisher={JMLR. org}
}

@inproceedings{Magliacane2018,
	title={Domain Adaptation by Using Causal Inference to Predict Invariant Conditional Distributions},
	author={Magliacane, Sara and van Ommen, Thijs and Claassen, Tom and Bongers, Stephan and Versteeg, Philip and Mooij, Joris M},
	booktitle={Advances in Neural Information Processing Systems},
	year={2018}
}

@article{Bareinboim2016,
	title={Causal inference and the data-fusion problem},
	author={Bareinboim, Elias and Pearl, Judea},
	journal={Proceedings of the National Academy of Sciences},
	volume={113},
	number={27},
	pages={7345--7352},
	year={2016},
	publisher={National Academy of Sciences of the United States of America}
}

@article{Peters2014,
	title={Causal Discovery with Continuous Additive Noise Models},
	author={Peters, Jonas and Mooij, Joris M and Janzing, Dominik and Sch{\"o}lkopf, Bernhard},
	journal={Journal of Machine Learning Research},
	volume={15},
	pages={2009--2053},
	year={2014}
}

@article{Scholkopf2021,
	title={Toward Causal Representation Learning},
	author={Sch{\"o}lkopf, Bernhard and Locatello, Francesco and Bauer, Stefan and Ke, Nan Rosemary and Kalchbrenner, Nal and Goyal, Anirudh and Bengio, Yoshua},
	journal={Proceedings of the IEEE},
	year={2021},
	publisher={IEEE}
}

@inproceedings{Courty2017,
	author = {Courty, Nicolas and Flamary, R\'{e}mi and Habrard, Amaury and Rakotomamonjy, Alain},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
	pages = {},
	publisher = {Curran Associates, Inc.},
	title = {Joint distribution optimal transportation for domain adaptation},
	volume = {30},
	year = {2017}
}

@article{Turrisi2020,
	title={Multi-source Domain Adaptation via Weighted Joint Distributions Optimal Transport},
	author={Turrisi, Rosanna and Flamary, R{\'e}mi and Rakotomamonjy, Alain and Pontil, Massimiliano},
	journal={arXiv preprint arXiv:2006.12938},
	year={2020}
}

@inproceedings{Chen2019,
	title={Temporal Attentive Alignment for Video Domain Adaptation},
	author={Min-Hung Chen and Zsolt Kira and Ghassan AlRegib},
	year={2019},
	eprint={1905.10861},
	archivePrefix={arXiv},
	primaryClass={cs.CV},
	booktitle =  {International Conference on Computer Vision (ICCV)}
}

@article{Liu2014,
	title = "Domain adaptation for land use classification: A spatio-temporal knowledge reusing method",
	journal = "ISPRS Journal of Photogrammetry and Remote Sensing",
	volume = "98",
	pages = "133 - 144",
	year = "2014",
	issn = "0924-2716",
	doi = "https://doi.org/10.1016/j.isprsjprs.2014.09.013",
	author = "Yilun Liu and Xia Li",
	keywords = "Domain adaptation, Transfer learning, Land use classification, -, , ",
	abstract = "Land use classification requires a significant amount of labeled data, which may be difficult and time consuming to obtain. On the other hand, without a sufficient number of training samples, conventional classifiers are unable to produce satisfactory classification results. This paper aims to overcome this issue by proposing a new model, TrCbrBoost, which uses old domain data to successfully train a classifier for mapping the land use types of target domain when new labeled data are unavailable. TrCbrBoost adopts a fuzzy CBR (Case Based Reasoning) model to estimate the land use probabilities for the target (new) domain, which are subsequently used to estimate the classifier performance. Source (old) domain samples are used to train the classifiers of a revised TrAdaBoost algorithm in which the weight of each sample is adjusted according to the classifier’s performance. This method is tested using time-series SPOT images for land use classification. Our experimental results indicate that TrCbrBoost is more effective than traditional classification models, provided that sufficient amount of old domain data is available. Under these conditions, the proposed method is 9.19% more accurate."
}

@article{Zhang2017,
	title={{FCN-rLSTM}: Deep Spatio-Temporal Neural Networks for Vehicle Counting in City Cameras},
	author={Shanghang Zhang and Guanhang Wu and Jo{\~a}o Paulo Costeira and Jos{\'e} M. F. Moura},
	journal={2017 IEEE International Conference on Computer Vision (ICCV)},
	year={2017},
	pages={3687-3696}
}

@inproceedings{Zhang2017b,
	title={Understanding traffic density from large-scale web camera data},
	author={Zhang, Shanghang and Wu, Guanhang and Costeira, Joao P and Moura, Jose MF},
	booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages={5898--5907},
	year={2017}
}

@article{Chan2008,
	title={Modeling, clustering, and segmenting video with mixtures of dynamic textures},
	author={Chan, Antoni B and Vasconcelos, Nuno},
	journal={IEEE transactions on pattern analysis and machine intelligence},
	volume={30},
	number={5},
	pages={909--926},
	year={2008},
	publisher={IEEE}
}

@inproceedings{Blanchard2011,
	author = {Blanchard, Gilles and Lee, Gyemin and Scott, Clayton},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {J. Shawe-Taylor and R. Zemel and P. Bartlett and F. Pereira and K. Q. Weinberger},
	pages = {},
	publisher = {Curran Associates, Inc.},
	title = {Generalizing from Several Related Classification Tasks to a New Unlabeled Sample},
	volume = {24},
	year = {2011}
}

@inproceedings{Muandet2013,
	title={Domain generalization via invariant feature representation},
	author={Muandet, Krikamol and Balduzzi, David and Sch{\"o}lkopf, Bernhard},
	booktitle={International Conference on Machine Learning},
	pages={10--18},
	year={2013},
	organization={PMLR}
}
