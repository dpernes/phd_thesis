% Appendix Template

\chapter{DeSIRe: Deep Signer-Invariant Representations for Sign Language Recognition -- supplementary material} % Main appendix title
\chaptermark{DeSIRe -- supplementary material}

\label{appendix:desire} % Change X to a consecutive letter; for referencing this appendix elsewhere, use \ref{AppendixX}

\section{Architecture}
\label{sec:desire_arch}
As shown in \Figref{fig:desire_arch}, the architecture of the DeSIRe model comprises a CVAE and a classifier.

\input{Figures/ChapterFour/fig_desire_arch.tex}

\subsection{CVAE}
The CVAE consists of an encoder and a decoder. The encoder network attempts to learn a stochastic mapping from an input image $\mX$, its class label $y$, and signer identity $s$ to a latent representation $\vz$. We condition the encoder on $y$ and $s$ by simply concatenating the class and signer identity as extra channels in the input image. In this case, both $y$ and $s$ are represented categorically using one-hot encoding. The encoder network then consists of a sequence of several $3\times 3$ convolutional layers with batch-normalization and leaky rectified linear units (LeakyReLUs) as non-linearities. For downsampling, the stride length of every convolution is set to 2. On top of that, there are two output fully connected (a.k.a.\ dense) layers, with linear activation functions, describing the mean $\vmu_e(\rmX,\ry,\rs; \vtheta_e)$ and the log-variance $\log \vsigma_e^2(\rmX,\ry,\rs; \vtheta_e)$ of the latent space distribution $q(\rvz \mid \rmX, \ry, \rs; \theta_e)$.

The decoder module will then generate a latent code $\vz$ by sampling from $q(\rvz \mid \mX, y, s; \theta_e)$ and proceed to the reconstruction of the original input $\mX$. In practice, the latent code $\vz$ is concatenated with a one-hot representation of the signer identity $s$ to be fed to the decoder network. The decoder network comprises several 2-D transposed convolutions for up-sampling and densifying the incoming activations. Every transposed convolutional layer is followed by batch-normalization and a LeakyReLU. The output layer also consists of a transposed convolutional layer but with a hyperbolic tangent activation function in order to output the reconstruction $\vmu_d(\vz,s; \vtheta_d)$ of the normalized input $\mX$.

\subsection{Classifier}
The implemented classifier module follows a typical CNN architecture for classification tasks. It starts with a block of convolutional layers for feature extraction purposes, producing representations $\tilde{\vz} \triangleq g(\mX;\vtheta_g)$. This is followed by a block of fully-connected layers for sign classification, which predicts the sign class $\hat{y} \triangleq h(\tilde{\vz};\vtheta_h)$. In particular, the convolutional block comprises a sequence of several pairs of consecutive $3 \times 3$ convolutional layers with ReLUs as non-linearities. For downsampling, the last convolutional layer of each pair has a stride of 2.

The fully-connected block consists of a sequence of fully-connected layers with ReLUs as the non-linear functions. The last fully-connected layer has a softmax activation function which outputs the probabilities for each sign class.

\section{Training strategies}
\label{sec:desire_training}

We have observed experimentally that the classification task is much easier than the reconstruction task of the CVAE. That is, the classifier tends to overfit the data with fewer training epochs than the CVAE, learning embeddings that are essentially not signer-invariant. In order to avoid this behavior, we have adopted an annealing strategy to define the classification weight $\lambda_2$. Specifically, at the start of training, this weight is set to zero, so that the CVAE learns to produce signer-invariant latent representations. At this stage, the CVAE behaves as a pure teacher model for the classifier network and, therefore, the $L_\text{emb}$ error is backpropagated only through the classifier. After a few epochs, the weight $\lambda_2$ starts increasing according to a sigmoid annealing schedule and the $L_\text{emb}$ loss starts to be backpropagated through the CVAE encoder as well. This procedure will endow the CVAE with a better sense of the classification task and hence promote class separability in the latent space. As a result, the model will be able to learn signer-invariant representations that are in fact highly discriminative for the sign recognition task.

Following \citet{Bowman2015} and in order to stabilize the training of the CVAE, we have employed a similar annealing strategy to define the KL divergence weights of the prior and signer-invariant loss terms, $\alpha_1$ and $\alpha_2$, respectively.

\section{Architecture and hyperparameter details}
All deep models were implemented in PyTorch and trained with the Adam optimization algorithm using a batch size of 32 samples. For reproducibility purposes, the source code as well as the weights of the trained models are publicly available online\footnote{URL will be made available after the decision.}.

The hyperparameters that are common to all the implemented models (i.e., the learning rate and the $\normltwo$ regularization coefficient) as well as some hyperparameters that are specific to the DeSIRe model (i.e.\ $\lambda_{1}$, $\lambda_{2}$, $\alpha_{1}$ and $\alpha_{2}$) and to the implemented Baseline~2 (i.e., $\gamma$) were optimized by means of a grid search approach and cross-validation on the training set. The hyperparameter of the $|\sS|$-nomial distribution $w(\rs \mid s_{i})$, defined for the proposed sampling scheme of the signer identity, was set as $\rho=0.5$. The dropout rate was empirically set at 0.5 for all the experiments. The set of values of the adopted hyperparameters grid search is presented in \Tableref{tab:desire_hyperparam}.

During the training stage of all the implemented models, besides $\normltwo$ regularization and dropout, a randomized data augmentation scheme was also employed. Following \citet{Ferreira2018}, the adopted data augmentation procedure is based on both geometric and colour transformations. The underlying idea is to further increase the robustness of the models to the wide range of hand gestures positions, poses, viewing angles as well as to different illumination conditions and contrasts.

\begin{table}[t]
    \centering
        \begin{tabular}{c|c|c}
            Hyperparameters                    & Acronym & Set                \\\hline
            Leaning rate                                & --       & \{$1\text{e}^{-03}$,$1\text{e}^{-04}$\}             \\
            $\ell^2$-norm coefficient                              & --      & \{$1\text{e}^{-04}$,$1\text{e}^{-05}$\}             \\
            $\mathcal{L}_{\text{triplet}}$ weight                 & $\gamma$                & \{0.1,0.5,1,5,10\}                  \\
            $\mathcal{L}_{\text{emb}}$ weight                 & $\lambda_{1}$                & \{0.1,0.5\}                  \\
            $\mathcal{L}_{\text{class}}$ weight                 & $\lambda_{2}$                & \{1,5,10\}                  \\
            $\mathcal{L}_{\text{prior}}$ weight                 & $\alpha_{1}$                & \{$5\text{e}^{-03}$, $8\text{e}^{-02}$\}                  \\
            $\mathcal{L}_{\text{signer\_inv}}$ weight                 & $\alpha_{2}$                & \{$8\text{e}^{-02}$, $4\text{e}^{-01}$, $8\text{e}^{-01}$\}                  \\
        \end{tabular}
    \caption{Hyperparameter sets for the DeSIRe model and baselines.}
    \label{tab:desire_hyperparam}
\end{table}


A detailed description of the architecture of the proposed model is presented in \Tableref{table:desire_arch}. For illustrative purposes, the presented DeSIRe architecture considers input colour images with a resolution of $100\times 100$ pixels, 10 signer identities in the training set and a total of 10 sign classes. It is important to stress out that, for a fair comparison, the topology of both implemented baselines follows the same architecture of the classifier component of the proposed DeSIRe model.

\begin{table}[t]
    \centering
        \begin{tabular}{c|c|c|c|c|c}
            \begin{tabular}[c]{@{}c@{}}Layer\\ \#\end{tabular} & \begin{tabular}[c]{@{}c@{}}DeSIRe\\ module\end{tabular} &Layer type  & \begin{tabular}[c]{@{}c@{}}Non-\\ linearity\end{tabular} & Output shape & Connected to                                                                    \\ \hline
            -                                                           & \multirow{4}{*}{\rotatebox[origin=c]{90}{Inputs}}                                         & input\_x                                                                           & -                                                                 & (3,100,100)           & -                                                                                        \\
            -                                                           &                                                                 & input\_y\_2d                                                                      & -                                                                 & (10,100,100)          & -                                                                                        \\
            -                                                           &                                                                 & input\_s\_2d                                                                     & -                                                                 & (10,100,100)          & -                                                                                        \\
            -                                                           &                                                                 & input\_s\_1d                                                                       & -                                                                 & (10,)                 & -                                                                                        \\ \hline
            1                                                           & \multirow{9}{*}{\rotatebox[origin=c]{90}{$q(\rvz \mid \rmX, \ry, \rs; \vtheta_e)$}}                                        & Concat2d-1                                                                      & -                                                                 & (23,100,100)          & \begin{tabular}[c]{@{}c@{}}{[}input\_x; \\ input\_y\_2d; \\ input\_s\_2d{]}\end{tabular} \\
            2                                                           &                                                                 & Conv2d-1                                                                         & LeakyReLU                                                         & (64,50,50)            & Concat2d-1                                                                               \\
            3                                                           &                                                                 & Conv2d-2                                                                        & LeakyReLU                                                         & (64,25,25)            & Conv2d-1                                                                                 \\
            4                                                           &                                                                 & Conv2d-3                                                                         & LeakyReLU                                                         & (128,13,13)           & Conv2d-2                                                                                 \\
            5                                                           &                                                                 & Conv2d-4                                                                        & LeakyReLU                                                         & (256,7,7)             & Conv2d-3                                                                                 \\
            6                                                           &                                                                 & Conv2d-5                                                                         & LeakyReLU                                                         & (512,4,4)             & Conv2d-4                                                                                 \\
            7                                                           &                                                                 & Dense-1                                                                          & Linear                                                            & (128,)                & Conv2d-5                                                                                 \\
            8                                                           &                                                                 & Dense-2                                                                        & Linear                                                            & (128,)                & Conv2d-5                                                                                 \\
            8                                                           &                                                                 & Dense-3                                                                         & LeakyReLU                                                         & (128,)                & \begin{tabular}[c]{@{}c@{}}{[}Dense-1; \\ Dense-2{]}\end{tabular}                        \\ \hline
            10                                                          & \multirow{7}{*}{\rotatebox[origin=c]{90}{$p(\rmX \mid \rvz, \rs; \vtheta_d)$}}                                        & Concat1d-1                                                                        & -                                                                 & (138,)                & \begin{tabular}[c]{@{}c@{}}{[}Dense-3; \\ input\_s\_1d{]}\end{tabular}                   \\
            11                                                          &                                                                 & Reshape-1                                                                        & -                                                                 & (512,4,4)             & Concat1d-1                                                                               \\
            12                                                          &                                                                 & ConvTr2d-1                                                               & LeakyReLU                                                         & (512,7,7)             & Reshape-1                                                                                \\
            13                                                          &                                                                 & ConvTr2d-2                                                                & LeakyReLU                                                         & (256,13,13)           & ConvTr2d-1                                                                        \\
            14                                                          &                                                                 & ConvTr2d-3                                                               & LeakyReLU                                                         & (128,25,25)           & ConvTr2d-2                                                                        \\
            15                                                          &                                                                 & ConvTr2d-4                                                                & LeakyReLU                                                         & (64,50,50)            & ConvTr2d-3                                                                        \\
            16                                                          &                                                                 & ConvTr2d-5                                                              & Tanh                                                              & (3,100,100)           & ConvTr2d-4                                                                        \\ \hline
            17                                                          & \multirow{6}{*}{\rotatebox[origin=c]{90}{$g(\mX; \vtheta_g)$}}                                           & Conv2d-6                                                                          & ReLU                                                              & (32,100,100)          & input\_x                                                                                 \\
            18                                                          &                                                                 & Conv2d-7                                                                        & ReLU                                                              & (32,50,50)            & Conv2d-6                                                                                 \\
            19                                                          &                                                                 & Conv2d-8                                                                          & ReLU                                                              & (64,50,50)            & Conv2d-7                                                                                 \\
            20                                                          &                                                                 & Conv2d-9                                                                         & ReLU                                                              & (64,25,25)            & Conv2d-8                                                                                 \\
            21                                                          &                                                                 & Conv2d-19                                                                          & ReLU                                                              & (128,13,13)           & Conv2d-9                                                                                 \\
            22                                                          &                                                                 & Conv2d-11                                                                         & ReLU                                                              & (128,13,13)           & Conv2d-10                                                                                 \\ \hline
            23                                                          & \multirow{5}{*}{\rotatebox[origin=c]{90}{$h(\tilde{\vz}; \vtheta_h)$}}                                          & Dense-4                                                                         & ReLU                                                              & (128,)                & Conv2d-11                                                                                \\
            24                                                          &                                                                 & Dropout-1                                                                         & -                                                                 & (128,)                & Dense-4                                                                                  \\
            25                                                          &                                                                 & Dense-5                                                                           & ReLU                                                              & (128,)                & Dropout-1                                                                                \\
            26                                                          &                                                                 & Dropout-2                                                                          & -                                                                 & (128,)                & Dense-5                                                                                  \\
            27                                                          &                                                                 & Dense-6                                                                          & Softmax                                                              & (10,)                 & Dropout-2                                                                                \\
        \end{tabular}
    \caption{A detailed description of the architecture of the proposed DeSIRe model. The output shape is described as (\#filters, rows, columns).}
    \label{table:desire_arch}
\end{table}