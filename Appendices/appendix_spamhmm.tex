% Appendix Template

\chapter{SpaMHMM -- supplementary material} % Main appendix title

\label{appendix:spamhmm} % Change X to a consecutive letter; for referencing this appendix elsewhere, use \ref{AppendixX}

\section{Derivation of \Algref{alg:mhmm} (MHMM training)}
\label{sec:proof_em_noreg}
\Algref{alg:mhmm} follows straightforwardly from applying EM to the model defined by \twoeqrefs{eq:spamhmm_density}{eq:spamhmm_hmm} with the objective \plaineqref{eq:spamhmm_log_likelihood}. Let us define the following notation: $\tX \coloneqq \left\lbrace \mX_i \right\rbrace_{i=1}^N$, $\vy \coloneqq \left\lbrace y_i \right\rbrace_{i=1}^N$, $\rvz \coloneqq \left\lbrace \rz_i \right\rbrace_{i=1}^N$ and $\rmH \coloneqq \left\lbrace \rvh_i \right\rbrace_{i=1}^N$. After building the usual variational lower bound for the log-likelihood and performing the E-step, we get the following well-known objective:
\begin{equation}
\label{m_step_obj_noreg}
\tilde{J}(\Theta,\Theta^{(-)}) \triangleq \sum_{\rvz,\rmH} p(\tX,\rvz,\rmH \mid \vy,\Theta^{(-)}) \log p(\tX,\rvz,\rmH \mid \vy,\Theta),
\end{equation}
which we want to maximize with respect to $\Theta$ and where $\Theta^{(-)}$ are the model parameters that were kept fixed in the E-step. Some of the parameters in the model are constrained to represent valid probabilities, yielding the following Lagrangian:
\begin{align}
\label{lagrangian_noreg}
L(\Theta,\Theta^{(-)},\Lambda) = &\tilde{J}(\Theta,\Theta^{(-)}) + \sum_k \lambda_k^{\text{mix}}\left(1 - ||\boldsymbol{\alpha}_k||_{1}\right) \nonumber\\
&+ \sum_{m,s} \lambda_{m,s}^\text{state} \left(1 - \sum_u A^m_{s,u}\right) \nonumber\\
&+ \sum_m \lambda_m^{\text{ini}} \left(1 - ||\boldsymbol{\pi}_m||_{1}\right),
\end{align}
where $\Lambda$ summarizes all Lagrange multipliers used here. Differentiating \eqref{lagrangian_noreg} with respect to each model parameter and Lagrange multiplier and solving for the critical points yields:

\begin{align}
	& \evalpha_{k,m} = \frac{\sum_i p(\rz_i=m |\mX_i,y_i,\Theta^{(-)}) \1_{y_i=k}}{\sum_i \1_{y_i=k}},\\
	& \evpi_{m,s} = \frac{\sum_i p(\rz_i=m \mid \mX_i,y_i,\Theta^{(-)}) p(\rh_i^{(0)}=s \mid \rz_i=m,\mX_i,y_i,\Theta^{(-)})}{\sum_i p(\rz_i=m \mid \rmX_i,y_i,\Theta^{(-)})}, \\
	\lefteqn{\emA^m_{s,u} =} \nonumber\\
	& \frac{\sum_i p(\rz_i=m \mid \mX_i,y_i,\Theta^{(-)}) \sum_{t=1}^{T_i} p(\rh_i^{(t-1)}=s, \rh_i^{(t)}=u \mid \rz_i=m,\mX_i,y_i,\Theta^{(-)})} {\sum_i p(\rz_i=m \mid \mX_i,y_i,\Theta^{(-)}) \sum_{t=1}^{T_i} p(\rh_i^{(t-1)}=s \mid \rz_i=m,\mX_i,y_i,\Theta^{(-)})}, \\
	& \vmu_{m,s} = \frac{\sum_i p(\rz_i=m \mid \mX_i,y_i,\Theta^{(-)}) \sum_{t=1}^{T_i} p(\rh_i^{(t)}=s \mid \rz_i=m,\mX_i,y_i,\Theta^{(-)}) \vx_i^{(t)}}{\sum_i p(\rz_i=m \mid \mX_i,y_i,\Theta^{(-)}) \sum_{t=1}^{T_i} p(\rh_i^{(t)}=s \mid \rz_i=m,\mX_i,y_i,\Theta^{(-)})}, \\
	\lefteqn{\vsigma^2_{m,s} =} \nonumber\\
	& \frac{\sum_i p(\rz_i=m \mid \mX_i,y_i,\Theta^{(-)}) \sum_{t=1}^{T_i} p(\rh_i^{(t)}=s \mid \rz_i=m,\mX_i,y_i,\Theta^{(-)}) \left(\vx_i^{(t)} - \boldsymbol{\mu}^m_s\right)^2}{\sum_i p(\rz_i=m \mid \mX_i,y_i,\Theta^{(-)}) \sum_{t=1}^{T_i} p(\rh_i^{(t)}=s \mid \rz_i=m,\mX_i,y_i,\Theta^{(-)})}, \\
	& \forall \, k,m,s,u. \nonumber
\end{align}
Defining $n_k$, $\rho_{i,m}$, $\gamma_{i,m,s}$ and $\xi_{i,m,s,u}$ as in \Algref{alg:mhmm} the result follows.

\section{Derivation of \Algref{alg:spamhmm} (SpaMHMM training)}
\label{sec:proof_em_reg}
Using the same notation as in \Secref{sec:proof_em_noreg}, we may rewrite \eqref{objective} as:
\begin{align}
J_r(\Theta) = &\frac{1}{N}\log \sum_{\rvz,\rmH} p(\tX,\rvz,\rmH \mid \vy,\Theta) \nonumber\\
& +\frac{\reg}{2} \sum_{j,k\neq j} \emG_{j,k} \E_{\rz \sim p(\rz \mid \ry=j, \Theta)} [ p(\rz \mid \ry=k, \Theta) ].
\end{align}
Despite the regularization term, we may still lower bound this objective by introducing a variational distribution $q(\rvz,\rmH)$ and using Jensen's inequality in the usual way:
\begin{align}
J_r(\Theta) &\geq \frac{1}{N} \E_{\rvz,\rmH \sim q} \left[\log \frac{p(\tX,\rvz,\rmH \mid \vy,\Theta)}{q(\rvz,\rmH)} \right] \nonumber\\
&\mathbin{\hphantom{=}}{} + \frac{\reg}{2} \sum_{j,k\neq j} \emG_{j,k} \E_{\rz \sim p(\rz \mid \ry=j, \Theta)} [ p(\rz \mid \ry=k, \Theta) ] \nonumber\\
&\coloneqq V_r(\Theta, q).
\end{align}
Clearly,
\begin{align}
\lefteqn{J_r(\Theta) - V_r(\Theta, q) =}\nonumber\\
&=\frac{1}{N} \left(\log p(\tX|\vy,\Theta) - \E_{\rvz,\rmH \sim q} \left[\log \frac{p(\tX,\rvz,\rmH \mid \vy,\Theta)}{q(\rvz,\rmH)} \right] \right) \nonumber\\
&= \frac{1}{N} \KL \left(q(\rvz,\rmH) || p(\rvz,\rmH \mid \tX,\vy,\Theta)  \right),
\end{align}
which, fixing the parameters $\Theta$ to some value $\Theta^{(-)}$ and minimizing with respect to $q$, yields the usual solution $q^*(\rvz,\rmH) = p(\rvz,\rmH \mid \tX,\vy,\Theta^{(-)})$. Thus, in the M-step, we want to find:
\begin{align}
\lefteqn{\argmax_\Theta V_r(\Theta, q^*) =} \nonumber\\
& =\argmax_\Theta \frac{1}{N}\sum_{\rvz,\rmH} p(\tX,\rvz,\rmH \mid \vy,\Theta^{(-)}) \log p(\tX,\rvz,\rmH \mid \vy,\Theta) \nonumber\\
& \mathbin{\hphantom{=}}{}+ \frac{\reg}{2} p(\tX|\vy,\Theta^{(-)}) \sum_{j,k\neq j} \emG_{j,k} \E_{\rz \sim p(\rz \mid \ry=j, \Theta)} [ p(\rz \mid \ry=k, \Theta) ] \nonumber\\
& = \argmax_\Theta \frac{1}{N}\tilde{J}(\Theta, \Theta^{(-)}) + \reg R(\Theta, \Theta^{(-)}) \nonumber\\
& \coloneqq \argmax_\Theta \tilde{J}_r(\Theta, \Theta^{(-)}),
\end{align}
where $\tilde{J}(\Theta, \Theta^{(-)})$ is as defined in \eqref{m_step_obj_noreg} and $R(\Theta, \Theta^{(-)})$ is our regularization (weighted by the data likelihood), which is simply a function of the parameters $\valpha_1,...,\valpha_K$:
\begin{align}
R(\Theta, \Theta^{(-)}) &= \frac{1}{2}p(\tX|\vy,\Theta^{(-)}) \sum_{j,k\neq j} \emG_{j,k} \E_{\rz \sim p(\rz \mid \ry=j, \Theta)} [ p(\rz \mid \ry=k, \Theta) ] \nonumber\\
&= \frac{1}{2}p(\tX|\vy,\Theta^{(-)}) \sum_{j,k\neq j} \emG_{j,k} \valpha_j \transp \valpha_k \nonumber\\
&= R(\valpha_1,...,\valpha_K,\Theta^{(-)}).
\end{align}
Now, we may build the Lagrangian as done in \Secref{sec:proof_em_noreg}. Since $R$ only depends on the $\valpha$'s, the update equations for the remaining parameters are unchanged. However, for the $\valpha$'s, it is not possible to obtain a closed form update equation. Thus, we use the reparameterization defined in \eqref{normalization} and update the new unconstrained parameters $\vbeta$ via gradient ascent. \\
We have:
\begin{align}
& \frac{\partial \tilde{J}}{\partial \alpha_{k,m}} = \frac{p(\tX|\vy,\Theta^{(-)})}{\alpha_{k,m}} \sum_i p(\rz_i=m \mid \mX_i,y_i,\Theta^{(-)}) \1_{y_i=k} \label{dJ_dalpha}, \\
& \frac{\partial R}{\partial \alpha_{k,m}} = p(\tX|\vy,\Theta^{(-)}) \sum_{j \neq k} \emG_{j,k} \alpha_{j,m}. \label{dR_dalpha}
\end{align}
From \twoeqrefs{dJ_dalpha}{dR_dalpha}, we see that the the resulting gradient $\nabla_{\boldsymbol{\alpha}_k} \tilde{J}_r = \frac{1}{N}\nabla_{\boldsymbol{\alpha}_k} \tilde{J} + \reg \nabla_{\boldsymbol{\alpha}_k} R$ is equal to some vector scaled by the joint data likelihood $p(\tX|\vy,\Theta^{(-)})$, which we discard since it only affects the learning rate, besides being usually very small and somewhat costly to compute. This option is equivalent to using a learning rate that changes at each iteration of the outter loop of the algorithm. \\
\Eqref{normalization} yields the following derivatives:
\begin{align}
& \frac{\partial \alpha_{k,m}}{\partial \beta_{k,m}} = \1_{\beta_{k,m} > 0} \frac{2\sigma'(\beta_{k,m})}{\sigma(\beta_{k,m})} \alpha_{k,m} (1 - \alpha_{k,m}), \\
& \frac{\partial \alpha_{k,m}}{\partial \beta_{k,l}} = \1_{\beta_{k,m} > 0} \frac{-2\sigma'(\beta_{k,m})}{\sigma(\beta_{k,m})} \alpha_{k,m} \alpha_{k,l}, \text{ for } l \neq m.
\end{align}
Finally, by the chain rule, we obtain:
\begin{align}
\lefteqn{\frac{\partial \tilde{J}}{\partial \beta_{k,m}} = \sum_l \frac{\partial \tilde{J}}{\partial \alpha_{k,l}} \frac{\partial \alpha_{k,l}}{\partial \beta_{k,m}}} \nonumber\\
&= \1_{\beta_{k,m} > 0} \frac{2\sigma'(\beta_{k,m})}{\sigma(\beta_{k,m})} \sum_i  \left(p(\rz_i=m \mid \mX_i,y_i,\Theta^{(-)}) -\alpha_{k,m}\right)\1_{y_i=k}, \\
\lefteqn{\frac{\partial R}{\partial \beta_{k,m}} = \sum_l \frac{\partial R}{\partial \alpha_{k,l}} \frac{\partial \alpha_{k,l}}{\partial \beta_{k,m}}} \nonumber\\
&= \1_{\beta_{k,m} > 0} \frac{2\sigma'(\beta_{k,m})}{\sigma(\beta_{k,m})} \alpha_{k,m}\sum_{j \neq k} \emG_{j,k}\left(\alpha_{j,m} - \valpha_j \transp \valpha_k \right).
\end{align}
Defining $\delta_{k,m} \coloneqq \frac{\partial \tilde{J}_r}{\partial \beta_{k,m}} = \frac{1}{N}\frac{\partial \tilde{J}}{\partial \beta_{k,m}} + \reg \frac{\partial R}{\partial \beta_{k,m}}$ and applying the gradient ascent update formula to $\beta_{k,m}$ the result follows.

\section{Getting the posterior distribution of observations in SpaMHMM}
\label{sec:posterior_proof}
In this section, we show how to obtain the posterior distribution $p(\rmX \mid \mX_\text{pref}, y)$ of sequences $\rmX \triangleq \left(\rvx^{(1)}, ...,\rvx^{(t)}\right)$ given an observed prefix sequence $\mX_\text{pref} \triangleq \left(\vx^{(-t_\text{pref}+1)}, ...,\vx^{(0)}\right)$, both coming from the graph node $y$. We start by writing this posterior as a marginalization with respect to the latent variable $\rz$:
\begin{align}
\label{mhmm_posterior}
p(\rmX \mid \mX_\text{pref}, y) &= \sum_{\rz} p(\rmX, \rz \mid \mX_\text{pref}, y)\nonumber\\
&= \sum_{\rz} p(\rmX \mid \mX_\text{pref}, y, \rz) p(\rz \mid \mX_\text{pref}, y) \nonumber\\
&= \sum_{\rz} p(\rmX \mid \mX_\text{pref}, \rz) p(\rz \mid \mX_\text{pref}, y),
\end{align}
where the last equality follows from the fact that the observations $\rmX$ are conitionally independent of the graph node $\ry$ given the latent variable $\rz$. The posterior $p(\rz \mid \mX_\text{pref}, y)$ may be obtained as done in \Algref{alg:mhmm}:
\begin{equation}
p(\rz \mid \mX_\text{pref}, y) \propto p(\mX_\text{pref} \mid z)p(z \mid y).
\end{equation}
We now focus on the computation of $p(\rmX \mid \mX_\text{pref}, \rz)$. Let $\rvh_\text{pref} \triangleq \left(\rh^{(-t_\text{pref}+1)}, ...,\rh^{(-1)}\right)$ and $\rvh \triangleq \left(\rh^{(0)}, ...,\rh^{(t)}\right)$, then:
\begin{align}
p(\rmX \mid \mX_\text{pref}, \rz) &= \sum_{\rvh_\text{pref}, \rvh} p(\rmX, \rvh_\text{pref}, \rvh \mid \mX_\text{pref}, \rz) \nonumber\\
&= \sum_{\rvh_\text{pref}, \rvh} p(\rmX \mid \rvh_\text{pref}, \rvh, \mX_\text{pref}, \rz) p(\rvh_\text{pref}, \rvh \mid \mX_\text{pref}, \rz) \nonumber\\
&= \sum_{\rvh_\text{pref}, \rvh} p(\rmX \mid \rvh, \rz) p(\rvh_\text{pref} \mid \rvh, \mX_\text{pref}, \rz) p(\rh \mid \mX_\text{pref}, \rz) \nonumber\\
&= \sum_{\rvh} p(\rmX \mid \rvh, \rz) p(\rvh \mid \mX_\text{pref}, \rz) \nonumber\\
&= \sum_{\rvh} p(\rh^{(0)} \mid \mX_\text{pref}, \rz) \prod_{\tau=1}^{t} p(\rh^{(\tau)} \mid \rh^{(\tau-1)}, \rz) p(\rvx^{(\tau)} \mid \rh^{(\tau)}, z),
\end{align}
where we have used the independence assumptions that characterize the HMM. Here, the initial state posteriors $p(\rh^{(0)} \mid \mX_\text{pref}, \rz)$ are actually the final state posteriors for the sequence $\mX_\text{pref}$ for each HMM in the mixture, so they can also be computed as indicated \Algref{alg:mhmm}.

Thus, we see that, in order to obtain the posterior $p(\rmX \mid \mX_\text{pref}, y)$, we only need to update the mixture coefficients $p(\rz \mid \mX_\text{pref}, y)$ and the initial state probabilities $p(\rh^{(0)} \mid \rz, \mX_\text{pref})$. All remaining parameters are unchanged.